{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdix5kGibBfd"
   },
   "source": [
    "<center>\n",
    "<hr style=\"border-width: 2px ; border-color: #9370DB\">\n",
    "<h1><font color='#BC8F8F'>Classification multi-classe: la méthode One-vs-One(OvO)</font></h1>\n",
    "<hr style=\"border-width: 2px ; border-color: #9370DB\">\n",
    "</center>\n",
    "<!-- <h2>Contexte</h2> -->\n",
    "<blockquote>\n",
    "  La méthode One-vs-One est une technique de classification multi-classe où les données sont séparées en paires de classes. Pour chaque paire de classes, un classificateur binaire est construit pour discriminer les exemples de la première classe des exemples de la deuxième classe. Le classificateur binaire est construit en utilisant un algorithme de classification binaire standard.\n",
    "    \n",
    "Une fois que tous les classificateurs binaires ont été construits, l'algorithme peut être utilisé pour classer les nouveaux exemples. Pour chaque paire de classes, le classificateur binaire correspondant est appliqué au nouvel exemple, ce qui donne un score pour chaque classe. Le score pour chaque classe est ensuite sommé pour chaque paire de classes, et la classe avec le score total le plus élevé est choisie comme étant la classe prédite pour l'exemple.\n",
    "<blockquote>\n",
    "Dans un problème de classification binaire, il y a deux classes possibles : la classe positive <strong>(P)</strong> et la classe négative <strong>(N)</strong>. Le modèle de classification binaire prédit pour chaque exemple s'il appartient à la classe <strong>P</strong>  ou <strong>N</strong> .\n",
    "\n",
    "* <strong>TP (True Positive)</strong> : c'est le nombre d'exemples qui appartiennent réellement à la classe P et qui sont prédits correctement par le modèle comme appartenant à la classe P. En d'autres termes, le modèle a correctement identifié ces exemples comme positifs.\n",
    "\n",
    "* <strong>TN (True Negative)</strong> : c'est le nombre d'exemples qui appartiennent réellement à la classe N et qui sont prédits correctement par le modèle comme appartenant à la classe N. En d'autres termes, le modèle a correctement identifié ces exemples comme négatifs.\n",
    "\n",
    "Par opposition, il y a également des faux positifs <strong>(FP)</strong> et des faux négatifs  <strong>(FN)</strong> :\n",
    "\n",
    "* <strong>FP (False Positive)</strong> : c'est le nombre d'exemples qui appartiennent réellement à la classe N mais qui sont prédits par le modèle comme appartenant à la classe P. En d'autres termes, le modèle a mal identifié ces exemples comme positifs alors qu'ils sont négatifs.\n",
    "\n",
    "* <strong>FN (False Negative)</strong> : c'est le nombre d'exemples qui appartiennent réellement à la classe P mais qui sont prédits par le modèle comme appartenant à la classe N. En d'autres termes, le modèle a mal identifié ces exemples comme négatifs alors qu'ils sont positifs.\n",
    "\n",
    "Les valeurs TP et TN sont importantes pour calculer des métriques d'évaluation telles que la précision, le rappel et la spécificité\n",
    "* L’accuracy, qui est la mesure de performance d’un modèle la plus intuitive, peut être définie à partir de ces termes : il s’agit tout simplement du ratio des observations correctes prédites sur le total des observations, soit : $$accuracy = \\frac{(TP+TN)}{(TP+TN+FP+FN)}.$$ C’est une métrique très efficace dans le cas de dataset équilibrés. <br>\n",
    "\n",
    "Pour les datasets déséquilibrés, les métriques couramment utilisées pour mesurer la performance des modèles sont :\n",
    "\n",
    "La combinaison de la Precision, du Recall, et du F1-score :\n",
    "* La Precision est le ratio des observations prédites positives correctement sur le total des observations prédites positives tout court, soit : $$ P = \\frac{TP}{TP + FP}$$. Cette métrique permet de voir à quel point nos prédictions positives tombent “juste”.\n",
    "* Le Recall (ou Sensitivity) est le ratio des observations prédites positives correctement sur l’ensemble des observations réellement positives, soit : $$ R = \\frac{TP}{TP + FN}$$. Cette métrique permet de mesurer à quel point l’on capture tous les vrais positifs dans nos prédictions.\n",
    "* Le F1-score est une moyenne pondérée de la Precision et du Recall. Son expression est : $$F_1 = \\frac{2*RP}{R+P}.$$ Cette métrique est en générale plus utile que l’accuracy, car elle prend en compte à la fois les faux positifs et les faux négatifs.<br>\n",
    "\n",
    "Les matrices de confusions sont des tables qui permettent de visualiser la performance d’un modèle en affichant les mesures des TP, TN, FP, et FN. Toutes les observations qui se situent sur la diagonale de la matrice ont été correctement prédites par le modèle, tandis que les observations qui ne se situent pas sur la diagonale correspondent à des erreurs du modèle. Un modèle parfait aurait donc l’ensemble de ses prédictions sur la diagonale d’une matrice de confusion. <center>\n",
    "<img src=\"https://static.packt-cdn.com/products/9781838555078/graphics/C13314_06_05.jpg\" alt=\"texte alternatif\" width=\"300\" height=\"250\"> <h6 style=\"text-align: center;\"><em><strong>Source:</strong>\n",
    "<a href=\"https://subscription.packtpub.com/book/big-data-and-business-intelligence/9781838555078/6/ch06lvl1sec34/confusion-matrix\">Basic representation of a confusion matrix</a></em></h6>\n",
    "</center>\n",
    "\n",
    "<!--<strong>L'AUC-ROC</strong> (Area Under the Curve of the Receiver Operating Characteristic) est une mesure de performance d'un modèle de classification binaire. L'objectif de cette métrique est de mesurer la capacité du modèle à distinguer les classes positives et négatives.<br>\n",
    "La courbe ROC est un graphique représentant la sensibilité (taux de vrais positifs) en fonction de la spécificité (taux de faux positifs) pour différents seuils de classification. La sensibilité est le pourcentage de vrais positifs (classe positive correctement prédite) parmi tous les exemples de la classe positive, tandis que la spécificité est le pourcentage de faux positifs (classe négative incorrectement prédite comme positive) parmi tous les exemples de la classe négative.<br>\n",
    "L'AUC-ROC mesure l'aire sous la courbe ROC, qui varie entre 0 et 1. Un modèle avec une AUC-ROC de 1 est parfaitement capable de distinguer les classes, tandis qu'un modèle avec une AUC-ROC de 0,5 est aussi performant qu'un classificateur aléatoire.<br>\n",
    "L'AUC-ROC est une métrique couramment utilisée en classification binaire pour comparer différents modèles et choisir le meilleur modèle pour une tâche donnée. Elle est particulièrement utile dans les cas où les classes ne sont pas équilibrées, c'est-à-dire lorsque l'une des classes est beaucoup plus fréquente que l'autre.-->\n",
    "<blockquote>\n",
    "    En résumé,\n",
    "    <ul>\n",
    "    <li> L'Accuracy : mesure la proportion de prédictions correctes parmi toutes les prédictions.</li> \n",
    "    <li> La Precision : mesure la proportion de vrais positifs parmi toutes les prédictions positives.</li> \n",
    "   <li> Le Recall : mesure la proportion de vrais positifs parmi toutes les instances positives.</li> \n",
    "   <li> Le F1-score : mesure la moyenne harmonique de precision et de recall.</li> \n",
    "   <li> La ROC AUC : mesure la capacité du modèle à distinguer entre les classes en tracant la courbe ROC et calculant la zone sous la courbe.</li> \n",
    "Les métriques suivantes sont importantes dans certains cas:\n",
    "   <li>Précision moyenne pondérée (weighted avg precision) : une moyenne pondérée de la précision pour chaque classe, pondérée par le nombre total d'exemples dans chaque classe.</li>\n",
    "   <li>Rappel moyen pondéré (weighted avg recall) : une moyenne pondérée du rappel pour chaque classe, pondérée par le nombre total d'exemples dans chaque classe.</li>\n",
    "   <li>Score F1 moyen pondéré (weighted avg f1-score) : une moyenne pondérée du score F1 pour chaque classe, pondérée par le nombre total d'exemples dans chaque classe.</li>\n",
    "    </ul>\n",
    "</blockquote>\n",
    "</blockquote>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0Q-wpkse7ZX"
   },
   "source": [
    "<center>\n",
    "<hr style=\"border-width: 2px ; border-color: #9370DB\">\n",
    "<h1><font color='#BC8F8F'>1.Préparation des données</font></h1>\n",
    "<hr style=\"border-width: 2px ; border-color: #9370DB\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45-4XQxAadFA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "#import xplotter\n",
    "sns.set_theme()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler,  ClusterCentroids\n",
    "from imblearn.metrics import classification_report_imbalanced, geometric_mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "otWghGj6adOy",
    "outputId": "34ebcacb-a098-43ed-cc01-8dc638dfa79b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109001, 48)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv('/gdrive/MyDrive/Jan23_BDS_Accidents/data/X_test.csv')\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VYxO7ssiadx1",
    "outputId": "81d522ff-68cf-4078-bc03-8c19009f1098"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254335, 48)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv('/gdrive/MyDrive/Jan23_BDS_Accidents/data/X_train.csv')\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LZtfIV30aeAg",
    "outputId": "d2013e68-2a1f-488f-b7a5-b573250f4eed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109001, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = pd.read_csv(\"/gdrive/MyDrive/Jan23_BDS_Accidents/data/y_test.csv\")\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlW-QVlfaeRN",
    "outputId": "d1df6d3a-d835-4d8d-81bb-7e347f1ee0eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254335, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.read_csv(\"/gdrive/MyDrive/Jan23_BDS_Accidents/data/y_train.csv\")\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hehQMpN1aeeU",
    "outputId": "726dd4cc-4836-449e-cc9a-f3434bff6771"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indemne               106191\n",
       "blessé_léger          102053\n",
       "blessé_hospitalisé     39474\n",
       "tué                     6617\n",
       "Name: gravite_accident, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.gravite_accident.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k7B1R-m4ae2d",
    "outputId": "91ca2ef3-fad0-4210-f775-ea92e228b781"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indemne               45511\n",
       "blessé_léger          43737\n",
       "blessé_hospitalisé    16918\n",
       "tué                    2835\n",
       "Name: gravite_accident, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.gravite_accident.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtFBWAc9kCsG"
   },
   "source": [
    "<blockquote>\n",
    "On se situe dans le cas où les classes sont déséquilibrées; les classes 'indemne' et 'blessé_léger' sont fortement majoritaires.\n",
    "La méthode OvO peut ne pas être la plus appropriée. En effet, les classificateurs binaires peuvent être biaisés vers les classes majoritaires, ce qui peut entraîner une mauvaise classification des classes minoritaires.\n",
    "\n",
    "Cependant, il existe plusieurs techniques pour gérer les classes déséquilibrées avec la méthode OvO:\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkzRGf2Mrmt5"
   },
   "source": [
    "<h3>a. Undersampling</h3>\n",
    "<blockquote>\n",
    "L'Undersampling (sous-échantillonnage): dans cette technique, nous réduisons le nombre de données dans les classes majoritaires pour qu'il soit similaire à celui des classes minoritaires. Cela permet de réduire le biais des classificateurs binaires vers les classes majoritaires.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xV2nT5hLvzbS",
    "outputId": "643debc6-dc63-4625-8758-9b48897f5b28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes échantillon rus : {'blessé_hospitalisé': 6617, 'blessé_léger': 6617, 'indemne': 6617, 'tué': 6617}\n"
     ]
    }
   ],
   "source": [
    "rUs = RandomUnderSampler()\n",
    "X_ru, y_ru = rUs.fit_resample(X_train, y_train)\n",
    "print('Classes échantillon rus :', dict(pd.Series(y_ru[\"gravite_accident\"]).value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1vgUcTTdKB1"
   },
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1cBh2NogwdC1"
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "id": "Hd-Lxg_5wejR",
    "outputId": "e6d60ff9-8637-45d9-efe0-29510d65c408"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsOneClassifier(estimator=RandomForestClassifier())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneVsOneClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsOneClassifier(estimator=RandomForestClassifier())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneVsOneClassifier(estimator=RandomForestClassifier())"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo_clf = OneVsOneClassifier(RandomForestClassifier()) #max_depth=10, random_state=0,min_samples_split=3\n",
    "ovo_clf.fit(X_ru, y_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dKKJN_xpwet_",
    "outputId": "abc96525-d339-4355-d7bc-15b2e7fcb0df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "blessé_hospitalisé       0.36      0.39      0.38     16918\n",
      "      blessé_léger       0.66      0.46      0.54     43737\n",
      "           indemne       0.72      0.69      0.71     45511\n",
      "               tué       0.10      0.58      0.17      2835\n",
      "\n",
      "          accuracy                           0.55    109001\n",
      "         macro avg       0.46      0.53      0.45    109001\n",
      "      weighted avg       0.63      0.55      0.58    109001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = ovo_clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40CZSoUAw3MH"
   },
   "source": [
    "<blockquote>\n",
    "Le modèle semble avoir des difficultés à prédire correctement la classe \"tué\". En effet, sa précision est très faible (0,10), ce qui signifie que le modèle a tendance à prédire cette classe à tort dans de nombreux cas. De plus, le rappel pour cette classe est relativement élevé (0,58), ce qui signifie que le modèle prédit cette classe correctement pour un certain nombre d'échantillons, mais qu'il en manque également beaucoup.\n",
    "\n",
    "Le f1-score pour la classe \"tué\" est également très faible (0,17), ce qui indique que le modèle a de la difficulté à trouver un équilibre entre la précision et le rappel pour cette classe. \n",
    "\n",
    "<!--Dans l'ensemble, ces mesures suggèrent que le modèle n'est pas performant pour la prédiction de la classe \"tué\" et qu'il pourrait être amélioré en utilisant des techniques telles que l'ajout de plus de données d'entraînement, l'ajustement des hyperparamètres du modèle ou en utilisant une méthode de classification différente.-->\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jR903GRL__rP"
   },
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5CP3j2zP__2i",
    "outputId": "ea546033-90a9-4047-8d65-8ea396837820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------RandomForestClassifier----------------------\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "blessé_hospitalisé       0.34      0.39      0.36     16918\n",
      "      blessé_léger       0.66      0.46      0.54     43737\n",
      "           indemne       0.72      0.69      0.70     45511\n",
      "               tué       0.10      0.59      0.17      2835\n",
      "\n",
      "          accuracy                           0.55    109001\n",
      "         macro avg       0.46      0.53      0.45    109001\n",
      "      weighted avg       0.62      0.55      0.57    109001\n",
      "\n",
      "-----------------------GradientBoostingClassifier----------------------\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "blessé_hospitalisé       0.35      0.40      0.37     16918\n",
      "      blessé_léger       0.68      0.43      0.53     43737\n",
      "           indemne       0.71      0.71      0.71     45511\n",
      "               tué       0.11      0.60      0.18      2835\n",
      "\n",
      "          accuracy                           0.55    109001\n",
      "         macro avg       0.46      0.54      0.45    109001\n",
      "      weighted avg       0.63      0.55      0.57    109001\n",
      "\n",
      "-----------------------LogisticRegression----------------------\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "blessé_hospitalisé       0.34      0.37      0.35     16918\n",
      "      blessé_léger       0.66      0.43      0.52     43737\n",
      "           indemne       0.70      0.70      0.70     45511\n",
      "               tué       0.09      0.58      0.16      2835\n",
      "\n",
      "          accuracy                           0.53    109001\n",
      "         macro avg       0.45      0.52      0.43    109001\n",
      "      weighted avg       0.61      0.53      0.56    109001\n",
      "\n",
      "-----------------------xgb.XGBClassifier----------------------\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "blessé_hospitalisé       0.34      0.38      0.36     16918\n",
      "      blessé_léger       0.64      0.44      0.52     43737\n",
      "           indemne       0.72      0.68      0.70     45511\n",
      "               tué       0.10      0.59      0.17      2835\n",
      "\n",
      "          accuracy                           0.53    109001\n",
      "         macro avg       0.45      0.52      0.44    109001\n",
      "      weighted avg       0.61      0.53      0.56    109001\n",
      "\n",
      "-----------------------CatBoostClassifier----------------------\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "blessé_hospitalisé       0.35      0.38      0.36     16918\n",
      "      blessé_léger       0.66      0.45      0.53     43737\n",
      "           indemne       0.73      0.69      0.71     45511\n",
      "               tué       0.10      0.61      0.17      2835\n",
      "\n",
      "          accuracy                           0.54    109001\n",
      "         macro avg       0.46      0.53      0.44    109001\n",
      "      weighted avg       0.62      0.54      0.57    109001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importer les modules nécessaires\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Définir les modèles à tester\n",
    "models = [\n",
    "    ('RandomForestClassifier', RandomForestClassifier()),#, params_rf),\n",
    "    ('GradientBoostingClassifier', GradientBoostingClassifier()),#, params_gb), ('SVC', SVC()),#, params_svm)\n",
    "    ('LogisticRegression',LogisticRegression()),\n",
    "    ('xgb.XGBClassifier',xgb.XGBClassifier()),\n",
    "    ('CatBoostClassifier',CatBoostClassifier(iterations=100,verbose = False))\n",
    "]\n",
    "\n",
    "# Boucle à travers chaque modèle et exécuter la recherche de grille\n",
    "best_model = None\n",
    "best_score = 0\n",
    "for name, model in models:\n",
    "    clf = OneVsOneClassifier(model)#GridSearchCV(model, params, cv=5))\n",
    "    clf.fit(X_ru, y_ru)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = metrics.classification_report(y_test, y_pred)\n",
    "    print(f\"-----------------------{name}----------------------\")\n",
    "    print()\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2BNWI700nbH"
   },
   "source": [
    "<blockquote>\n",
    "En se basant sur les résultats présentés, il est difficile de déclarer définitivement un modèle comme étant le \"meilleur\" car les métriques de performance (précision, rappel, score F1 et précision globale) sont similaires pour tous les modèles. Cependant, le modèle CatBoostClassifier a la précision et le rappel les plus élevés pour la classe \"tué\", qui est la classe avec les performances les plus faibles pour tous les modèles. Par conséquent, il peut être intéressant d'explorer plus en profondeur le modèle CatBoostClassifier.\n",
    "\n",
    "<!-- pour voir s'il surpasse régulièrement les autres modèles sur d'autres ensembles de données ou s'il y a d'autres facteurs à considérer tels que le temps de calcul et la complexité du modèle -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-e4dvzmXj40"
   },
   "source": [
    "Le programme suivant nous permettra de voir les résultats pour les classifications binaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vo6n3A6_1XH7",
    "outputId": "332cfaec-cff8-46cb-bae1-0514b138b181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Les performances du OvO prenant en argument CatBoostClassifier---------------\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "blessé_hospitalisé       0.36      0.38      0.37     16918\n",
      "      blessé_léger       0.65      0.45      0.53     43737\n",
      "           indemne       0.73      0.69      0.71     45511\n",
      "               tué       0.10      0.61      0.17      2835\n",
      "\n",
      "          accuracy                           0.55    109001\n",
      "         macro avg       0.46      0.53      0.45    109001\n",
      "      weighted avg       0.62      0.55      0.57    109001\n",
      "\n",
      "\n",
      "--------Les performances des classifieurs binaires pour chaque paire de classes--------------\n",
      "\n",
      "--------- Modalités ('tué', 'indemne')----------:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.72      0.44     16918\n",
      "           1       0.43      0.69      0.52     43737\n",
      "           2       0.00      0.00      0.00     45511\n",
      "           3       0.00      0.00      0.00      2835\n",
      "\n",
      "    accuracy                           0.39    109001\n",
      "   macro avg       0.19      0.35      0.24    109001\n",
      "weighted avg       0.22      0.39      0.28    109001\n",
      "\n",
      "\n",
      "--------- Modalités ('tué', 'blessé_léger')----------:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.84      0.43     16918\n",
      "           1       0.31      0.42      0.36     43737\n",
      "           2       0.00      0.00      0.00     45511\n",
      "           3       0.00      0.00      0.00      2835\n",
      "\n",
      "    accuracy                           0.30    109001\n",
      "   macro avg       0.15      0.32      0.20    109001\n",
      "weighted avg       0.17      0.30      0.21    109001\n",
      "\n",
      "\n",
      "--------- Modalités ('tué', 'blessé_hospitalisé')----------:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.62      0.23     16918\n",
      "           1       0.31      0.24      0.27     43737\n",
      "           2       0.00      0.00      0.00     45511\n",
      "           3       0.00      0.00      0.00      2835\n",
      "\n",
      "    accuracy                           0.19    109001\n",
      "   macro avg       0.11      0.21      0.12    109001\n",
      "weighted avg       0.14      0.19      0.14    109001\n",
      "\n",
      "\n",
      "--------- Modalités ('indemne', 'blessé_léger')----------:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.79      0.36     16918\n",
      "           1       0.24      0.28      0.26     43737\n",
      "           2       0.00      0.00      0.00     45511\n",
      "           3       0.00      0.00      0.00      2835\n",
      "\n",
      "    accuracy                           0.24    109001\n",
      "   macro avg       0.12      0.27      0.15    109001\n",
      "weighted avg       0.13      0.24      0.16    109001\n",
      "\n",
      "\n",
      "--------- Modalités ('indemne', 'blessé_hospitalisé')----------:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.40      0.14     16918\n",
      "           1       0.31      0.22      0.26     43737\n",
      "           2       0.00      0.00      0.00     45511\n",
      "           3       0.00      0.00      0.00      2835\n",
      "\n",
      "    accuracy                           0.15    109001\n",
      "   macro avg       0.10      0.16      0.10    109001\n",
      "weighted avg       0.14      0.15      0.13    109001\n",
      "\n",
      "\n",
      "--------- Modalités ('blessé_léger', 'blessé_hospitalisé')----------:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.20      0.08     16918\n",
      "           1       0.48      0.49      0.48     43737\n",
      "           2       0.00      0.00      0.00     45511\n",
      "           3       0.00      0.00      0.00      2835\n",
      "\n",
      "    accuracy                           0.23    109001\n",
      "   macro avg       0.13      0.17      0.14    109001\n",
      "weighted avg       0.20      0.23      0.21    109001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "essai_train = le.fit_transform(y_train) #encoder y_train\n",
    "essai_test = le.fit_transform(y_test) #encoder y_test\n",
    "\n",
    "#récupération des modalités décodées\n",
    "decoded_labels = le.inverse_transform(essai_test) \n",
    "modalites = list(set(decoded_labels))\n",
    "\n",
    "################################################################\n",
    "#On pouvait faire modalites = list(set(y_train.gravite_accident)) \n",
    "#from itertools import combinations\n",
    "#modals_pairs = list(combinations(modalites,2))\n",
    "#################################################################\n",
    "\n",
    "modal_pairs = [(modalites[i], modalites[j]) for i in range(4) for j in range(i+1, 4)]\n",
    "\n",
    "# Créer un classifieur \"One-vs-One\" à l'aide de la régression logistique\n",
    "clf = OneVsOneClassifier(CatBoostClassifier(iterations=100,verbose = False))\n",
    "\n",
    "# Ajuster le classifieur aux données\n",
    "clf.fit(X_ru, y_ru)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"-------------Les performances du OvO prenant en argument CatBoostClassifier---------------\")\n",
    "print()\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print()\n",
    "print(\"--------Les performances des classifieurs binaires pour chaque paire de classes--------------\")\n",
    "print()\n",
    "classifiers = clf.estimators_\n",
    "for i in range(len(modal_pairs)):\n",
    "    print(f\"--------- Modalités {modal_pairs[i]}----------:\")\n",
    "    print()\n",
    "    binary_clf = classifiers[i]\n",
    "    y_pred = binary_clf.predict(X_test)\n",
    "    #print(binary_clf)\n",
    "    print(metrics.classification_report(essai_test, y_pred))\n",
    "    #print(accuracy_score(y_test, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OaC0_1qX8ck"
   },
   "source": [
    "<blockquote>\n",
    "Les résultats de la classification multiclasse montrent une précision pondérée de 0,62, un rappel pondéré de 0,55 et une F1-pondérée de 0,57.\n",
    "\n",
    "En ce qui concerne les résultats de la classification binaire, il y a six paires de classes différentes dans notre sortie, chacune ayant ses propres résultats de précision, de rappel et de F1-score. Il semble que la paire de classes avec la meilleure performance est celle avec \"tué\" et \"indemne\", ayant une précision de 0,43, un rappel de 0,69 et un F1-score de 0,52. Cependant, toutes les autres paires de classes ont des performances inférieures, avec des F1-scores allant de 0 à 0,48."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2_MWkalBd36"
   },
   "source": [
    "<blockquote>\n",
    "Dans ce qui suit, on va entrainer le modèle Catboost de deux manières différentes:\n",
    "\n",
    "* On entrera le modèle **catboost** sans faire un **Undersampling** et sans sans appliquer le modèle **OnevOneClassifier**.\n",
    "* Nous allons entrainer le modèle **OnevOneClassifier**  qui prendra en argument le modèle **catboost** sans faire encore un **Undersampling**.\n",
    "\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W36GWU7LAABu",
    "outputId": "66ffae2d-22c7-4267-ba7d-ea6d78c0daa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "blessé_hospitalisé       0.50      0.38      0.43     16918\n",
      "      blessé_léger       0.63      0.64      0.63     43737\n",
      "           indemne       0.70      0.79      0.74     45511\n",
      "               tué       0.40      0.04      0.07      2835\n",
      "\n",
      "          accuracy                           0.64    109001\n",
      "         macro avg       0.56      0.46      0.47    109001\n",
      "      weighted avg       0.63      0.64      0.63    109001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "essai_train = le.fit_transform(y_train) #encoder y_train\n",
    "essai_test = le.fit_transform(y_test) #encoder y_test\n",
    "model = CatBoostClassifier(iterations=100,verbose = False)\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction sur les données de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Évaluation des performances du modèle\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LnkZBXQS77y3",
    "outputId": "a25da2b9-ab15-4cb5-e81c-fba59b721826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "blessé_hospitalisé       0.50      0.37      0.43     16918\n",
      "      blessé_léger       0.63      0.64      0.63     43737\n",
      "           indemne       0.70      0.79      0.74     45511\n",
      "               tué       0.40      0.04      0.08      2835\n",
      "\n",
      "          accuracy                           0.64    109001\n",
      "         macro avg       0.56      0.46      0.47    109001\n",
      "      weighted avg       0.63      0.64      0.63    109001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "essai_train = le.fit_transform(y_train) #encoder y_train\n",
    "essai_test = le.fit_transform(y_test) #encoder y_test\n",
    "model = CatBoostClassifier(iterations=100,verbose = False)\n",
    "# Entraînement du modèle\n",
    "ova = OneVsRestClassifier(model)\n",
    "ova.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction sur les données de test\n",
    "y_pred = ova.predict(X_test)\n",
    "\n",
    "# Évaluation des performances du modèle\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzlZE8jrGrIq"
   },
   "source": [
    "<blockquote>\n",
    "Les résultats pour la classe \"tué\" sont similaires pour chaque modèle.\n",
    "Nous pouvons remarquer que la précision de la classe \"tué\" est améliorée pour le deuxième modèle par contre son rappel est très bas: Ce qui veut dire que La classe n'est pas bien détectée.\n",
    "\n",
    "Cependant, si on considère l'ensemble des classes, le deuxième modèle semble avoir de meilleures performances que le premier. En effet, le deuxième modèle a une précision moyenne plus élevée pour chaque classe, un rappel plus élevé pour la classe \"blessé_hospitalisé\", un f1-score plus élevé pour la classe \"indemne\", et une meilleure précision globale et un f1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1R8SNSIZQ5h"
   },
   "source": [
    "<blockquote>\n",
    "\n",
    "Nous allons optimiser le modèle OnevOneClassifier qui prendra en argument le modèle catboost en faisant un **Undersampling**. En effet, celui prend plus en compte les classes minoritaires. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AS6C0Yxi7E4R"
   },
   "outputs": [],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJbKA0TFY-AO"
   },
   "outputs": [],
   "source": [
    "from optuna import Trial, visualization\n",
    "import optuna\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             balanced_accuracy_score,\n",
    "                             precision_score,\n",
    "                             recall_score,\n",
    "                             f1_score,\n",
    "                             confusion_matrix,\n",
    "                             ConfusionMatrixDisplay,\n",
    "                             classification_report,\n",
    "                             fbeta_score,\n",
    "                             make_scorer,\n",
    "                             precision_recall_fscore_support,\n",
    "                             roc_auc_score, roc_curve,\n",
    "                             precision_recall_curve, auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3ID-aH0Y9yP"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 0.1),\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-6, 10),\n",
    "        'bagging_temperature': trial.suggest_uniform('bagging_temperature', 0, 1),\n",
    "        'random_strength': trial.suggest_uniform('random_strength', 0, 1),\n",
    "        'od_type': 'Iter',\n",
    "        'od_wait': 50,\n",
    "        'allow_writing_files': False\n",
    "    }\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X_ru, y_ru, verbose=False)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qYI15FGOaxDe",
    "outputId": "1e332df4-e235-4733-a0e3-e83b011a464e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-16 12:36:06,751]\u001b[0m A new study created in memory with name: catboost\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:36:13,577]\u001b[0m Trial 0 finished with value: 0.5571233291437693 and parameters: {'iterations': 236, 'learning_rate': 0.07099837754199091, 'depth': 6, 'l2_leaf_reg': 0.014981549152262073, 'bagging_temperature': 0.7736236378498362, 'random_strength': 0.6019673298744607}. Best is trial 0 with value: 0.5571233291437693.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:36:20,739]\u001b[0m Trial 1 finished with value: 0.5550224309868717 and parameters: {'iterations': 156, 'learning_rate': 0.05589759869381682, 'depth': 7, 'l2_leaf_reg': 9.599591097487052e-05, 'bagging_temperature': 0.9430705707627097, 'random_strength': 0.12594433748858913}. Best is trial 0 with value: 0.5571233291437693.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:36:24,930]\u001b[0m Trial 2 finished with value: 0.5540407886166182 and parameters: {'iterations': 137, 'learning_rate': 0.046150597083760354, 'depth': 7, 'l2_leaf_reg': 0.0019708111604765806, 'bagging_temperature': 0.5154375974058595, 'random_strength': 0.37698896908769997}. Best is trial 0 with value: 0.5571233291437693.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:36:28,022]\u001b[0m Trial 3 finished with value: 0.5415454904083449 and parameters: {'iterations': 171, 'learning_rate': 0.022857130219369297, 'depth': 5, 'l2_leaf_reg': 0.0005035316936426886, 'bagging_temperature': 0.01805536412518205, 'random_strength': 0.9722757761028468}. Best is trial 0 with value: 0.5571233291437693.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:36:39,023]\u001b[0m Trial 4 finished with value: 0.5467105806368749 and parameters: {'iterations': 573, 'learning_rate': 0.011948152889280778, 'depth': 4, 'l2_leaf_reg': 0.00010526914077268328, 'bagging_temperature': 0.8626809186228339, 'random_strength': 0.6897381080955005}. Best is trial 0 with value: 0.5571233291437693.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:38:34,725]\u001b[0m Trial 5 finished with value: 0.5351418794322987 and parameters: {'iterations': 754, 'learning_rate': 0.09846710204041695, 'depth': 10, 'l2_leaf_reg': 0.05210556352606368, 'bagging_temperature': 0.33703662527240963, 'random_strength': 0.8762859428038706}. Best is trial 0 with value: 0.5571233291437693.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:38:38,199]\u001b[0m Trial 6 finished with value: 0.5556187557912313 and parameters: {'iterations': 197, 'learning_rate': 0.04890322901275422, 'depth': 5, 'l2_leaf_reg': 3.6110476428583696e-05, 'bagging_temperature': 0.36095743388278134, 'random_strength': 0.5121124000023178}. Best is trial 0 with value: 0.5571233291437693.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:39:08,423]\u001b[0m Trial 7 finished with value: 0.555150870175503 and parameters: {'iterations': 850, 'learning_rate': 0.050270088857971226, 'depth': 7, 'l2_leaf_reg': 0.019410989159193426, 'bagging_temperature': 0.6385210490563118, 'random_strength': 0.2639723866467588}. Best is trial 0 with value: 0.5571233291437693.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:39:53,511]\u001b[0m Trial 8 finished with value: 0.5551049990367061 and parameters: {'iterations': 780, 'learning_rate': 0.035343892985966394, 'depth': 8, 'l2_leaf_reg': 0.021497885903207774, 'bagging_temperature': 0.881034389139764, 'random_strength': 0.6401972354518906}. Best is trial 0 with value: 0.5571233291437693.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:40:04,082]\u001b[0m Trial 9 finished with value: 0.5597930294217485 and parameters: {'iterations': 613, 'learning_rate': 0.06491825586683836, 'depth': 4, 'l2_leaf_reg': 2.6082902638270913e-06, 'bagging_temperature': 0.03650281133468447, 'random_strength': 0.41327841302218093}. Best is trial 9 with value: 0.5597930294217485.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:40:18,719]\u001b[0m Trial 10 finished with value: 0.5590223942899606 and parameters: {'iterations': 989, 'learning_rate': 0.07514235813953778, 'depth': 3, 'l2_leaf_reg': 1.2369518860399238e-06, 'bagging_temperature': 0.00966814278158127, 'random_strength': 0.0039343748725652605}. Best is trial 9 with value: 0.5597930294217485.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:40:33,218]\u001b[0m Trial 11 finished with value: 0.5590315685177201 and parameters: {'iterations': 984, 'learning_rate': 0.07344391330167148, 'depth': 3, 'l2_leaf_reg': 1.4504133368983752e-06, 'bagging_temperature': 0.015704316540343807, 'random_strength': 0.03391892835264736}. Best is trial 9 with value: 0.5597930294217485.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:40:41,145]\u001b[0m Trial 12 finished with value: 0.5577104797203696 and parameters: {'iterations': 418, 'learning_rate': 0.07240593956129973, 'depth': 3, 'l2_leaf_reg': 1.7353649227684263e-06, 'bagging_temperature': 0.1544952097164271, 'random_strength': 0.257773187117756}. Best is trial 9 with value: 0.5597930294217485.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:40:48,912]\u001b[0m Trial 13 finished with value: 0.5582884560692104 and parameters: {'iterations': 560, 'learning_rate': 0.08574793693738593, 'depth': 4, 'l2_leaf_reg': 1.015957768504645, 'bagging_temperature': 0.1802945783302513, 'random_strength': 0.00019367968393246837}. Best is trial 9 with value: 0.5597930294217485.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:41:03,305]\u001b[0m Trial 14 finished with value: 0.5593434922615389 and parameters: {'iterations': 975, 'learning_rate': 0.062158252638652524, 'depth': 3, 'l2_leaf_reg': 6.568605792883145e-06, 'bagging_temperature': 0.15202520514310636, 'random_strength': 0.3451307144704484}. Best is trial 9 with value: 0.5597930294217485.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:41:13,126]\u001b[0m Trial 15 finished with value: 0.5592425757561857 and parameters: {'iterations': 407, 'learning_rate': 0.0644709087951251, 'depth': 5, 'l2_leaf_reg': 1.2634845466820745e-05, 'bagging_temperature': 0.2037382628726604, 'random_strength': 0.4354753322833071}. Best is trial 9 with value: 0.5597930294217485.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:41:25,032]\u001b[0m Trial 16 finished with value: 0.5593526664892983 and parameters: {'iterations': 642, 'learning_rate': 0.06163236683776686, 'depth': 4, 'l2_leaf_reg': 8.178049480401247e-06, 'bagging_temperature': 0.3516898296708002, 'random_strength': 0.34310491776906316}. Best is trial 9 with value: 0.5597930294217485.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:42:23,947]\u001b[0m Trial 17 finished with value: 0.5521600719259456 and parameters: {'iterations': 662, 'learning_rate': 0.040021596555885254, 'depth': 9, 'l2_leaf_reg': 1.1238765813904993e-05, 'bagging_temperature': 0.3330279946842655, 'random_strength': 0.5178151663476117}. Best is trial 9 with value: 0.5597930294217485.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:42:30,580]\u001b[0m Trial 18 finished with value: 0.5599214686103797 and parameters: {'iterations': 469, 'learning_rate': 0.08513124073621164, 'depth': 4, 'l2_leaf_reg': 0.00013890472488627565, 'bagging_temperature': 0.45895570631203086, 'random_strength': 0.19388920766315942}. Best is trial 18 with value: 0.5599214686103797.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:42:42,163]\u001b[0m Trial 19 finished with value: 0.557526995165182 and parameters: {'iterations': 418, 'learning_rate': 0.08339705710498943, 'depth': 6, 'l2_leaf_reg': 0.00024531046132113477, 'bagging_temperature': 0.5119922845230379, 'random_strength': 0.16731006437284734}. Best is trial 18 with value: 0.5599214686103797.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:42:50,249]\u001b[0m Trial 20 finished with value: 0.5581141457417822 and parameters: {'iterations': 346, 'learning_rate': 0.09675240167449181, 'depth': 5, 'l2_leaf_reg': 0.0008188247371968319, 'bagging_temperature': 0.6252407129189174, 'random_strength': 0.2205255453063339}. Best is trial 18 with value: 0.5599214686103797.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:42:59,988]\u001b[0m Trial 21 finished with value: 0.5600957789378079 and parameters: {'iterations': 647, 'learning_rate': 0.0619796190621747, 'depth': 4, 'l2_leaf_reg': 3.323514901830856e-05, 'bagging_temperature': 0.41050198844663544, 'random_strength': 0.33566585951937267}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:43:10,059]\u001b[0m Trial 22 finished with value: 0.5597746809662296 and parameters: {'iterations': 508, 'learning_rate': 0.08304716854368215, 'depth': 4, 'l2_leaf_reg': 4.9255372441336976e-05, 'bagging_temperature': 0.44085624452467953, 'random_strength': 0.41718834060901644}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:43:22,101]\u001b[0m Trial 23 finished with value: 0.5596737644608765 and parameters: {'iterations': 654, 'learning_rate': 0.05677535021565651, 'depth': 4, 'l2_leaf_reg': 2.509482920028691e-05, 'bagging_temperature': 0.25389594831826134, 'random_strength': 0.31656066304297903}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:43:35,731]\u001b[0m Trial 24 finished with value: 0.5583710241190448 and parameters: {'iterations': 514, 'learning_rate': 0.06754640637172102, 'depth': 6, 'l2_leaf_reg': 0.0001993832967948754, 'bagging_temperature': 0.4351259537176354, 'random_strength': 0.13988471066163466}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:43:50,583]\u001b[0m Trial 25 finished with value: 0.5568664507665068 and parameters: {'iterations': 727, 'learning_rate': 0.08936641954555939, 'depth': 5, 'l2_leaf_reg': 4.622102176015514e-06, 'bagging_temperature': 0.09771408891983036, 'random_strength': 0.2653649439456949}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:43:59,015]\u001b[0m Trial 26 finished with value: 0.5597563325107109 and parameters: {'iterations': 596, 'learning_rate': 0.07897026390207847, 'depth': 4, 'l2_leaf_reg': 4.562509153033727e-05, 'bagging_temperature': 0.6074872147323352, 'random_strength': 0.4369397805474674}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:44:05,685]\u001b[0m Trial 27 finished with value: 0.5563985651507785 and parameters: {'iterations': 306, 'learning_rate': 0.06663078820475238, 'depth': 3, 'l2_leaf_reg': 3.6368200748667902e-06, 'bagging_temperature': 0.25312872856594115, 'random_strength': 0.1955691009525312}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:44:23,223]\u001b[0m Trial 28 finished with value: 0.5542242731718058 and parameters: {'iterations': 709, 'learning_rate': 0.0777903988275171, 'depth': 6, 'l2_leaf_reg': 1.3156082941433331e-05, 'bagging_temperature': 0.2579918046396802, 'random_strength': 0.3235755404430347}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:44:43,708]\u001b[0m Trial 29 finished with value: 0.5543068412216402 and parameters: {'iterations': 830, 'learning_rate': 0.0695213281171767, 'depth': 6, 'l2_leaf_reg': 0.0027944130606702947, 'bagging_temperature': 0.7117837013490216, 'random_strength': 0.09201218483951046}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:44:54,045]\u001b[0m Trial 30 finished with value: 0.5584168952578417 and parameters: {'iterations': 474, 'learning_rate': 0.09044283873044438, 'depth': 5, 'l2_leaf_reg': 0.00010457576362848969, 'bagging_temperature': 0.09080625571503945, 'random_strength': 0.23116937817441674}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:45:03,736]\u001b[0m Trial 31 finished with value: 0.5596278933220796 and parameters: {'iterations': 483, 'learning_rate': 0.08043559985945554, 'depth': 4, 'l2_leaf_reg': 3.0954692026416784e-05, 'bagging_temperature': 0.4585069886466069, 'random_strength': 0.4619019220886945}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:45:08,026]\u001b[0m Trial 32 finished with value: 0.5582242364748947 and parameters: {'iterations': 289, 'learning_rate': 0.07418216473104472, 'depth': 4, 'l2_leaf_reg': 6.066200082336624e-05, 'bagging_temperature': 0.43301538476308904, 'random_strength': 0.39561311385366993}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:45:17,068]\u001b[0m Trial 33 finished with value: 0.5581875395638572 and parameters: {'iterations': 507, 'learning_rate': 0.08434956386029183, 'depth': 3, 'l2_leaf_reg': 0.00026272053961303544, 'bagging_temperature': 0.5631797801478792, 'random_strength': 0.3879914082940811}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:45:25,839]\u001b[0m Trial 34 finished with value: 0.559297621122742 and parameters: {'iterations': 616, 'learning_rate': 0.057291625381807966, 'depth': 4, 'l2_leaf_reg': 3.0979663793878203e-06, 'bagging_temperature': 0.4808566583212692, 'random_strength': 0.5491747438356227}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:45:36,346]\u001b[0m Trial 35 finished with value: 0.5594077118558546 and parameters: {'iterations': 453, 'learning_rate': 0.06980453374144975, 'depth': 5, 'l2_leaf_reg': 1.9480206978173776e-05, 'bagging_temperature': 0.40803201920416676, 'random_strength': 0.4566868159660471}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:45:56,686]\u001b[0m Trial 36 finished with value: 0.5515178759827891 and parameters: {'iterations': 362, 'learning_rate': 0.09120274767722221, 'depth': 8, 'l2_leaf_reg': 0.0010614976311437367, 'bagging_temperature': 0.5491346877156047, 'random_strength': 0.30335553856341274}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:46:00,586]\u001b[0m Trial 37 finished with value: 0.550013302630251 and parameters: {'iterations': 102, 'learning_rate': 0.08134550542780192, 'depth': 4, 'l2_leaf_reg': 0.00013889546906543888, 'bagging_temperature': 0.40323599866965737, 'random_strength': 0.3866536135972787}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:46:07,173]\u001b[0m Trial 38 finished with value: 0.5580591003752259 and parameters: {'iterations': 536, 'learning_rate': 0.05894138733221852, 'depth': 3, 'l2_leaf_reg': 5.340231188072122e-05, 'bagging_temperature': 0.5082972942270607, 'random_strength': 0.5719367365420467}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:46:21,573]\u001b[0m Trial 39 finished with value: 0.5579765323253915 and parameters: {'iterations': 697, 'learning_rate': 0.05233154304311266, 'depth': 5, 'l2_leaf_reg': 8.404542301962291e-05, 'bagging_temperature': 0.32705927647275823, 'random_strength': 0.18242081309961738}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:46:32,332]\u001b[0m Trial 40 finished with value: 0.5600223851157329 and parameters: {'iterations': 560, 'learning_rate': 0.07780830118965269, 'depth': 4, 'l2_leaf_reg': 0.00030699082813891637, 'bagging_temperature': 0.7387837439111322, 'random_strength': 0.4951213114516618}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:46:41,638]\u001b[0m Trial 41 finished with value: 0.5596829386886358 and parameters: {'iterations': 576, 'learning_rate': 0.07589971962001564, 'depth': 4, 'l2_leaf_reg': 0.00038709906714720746, 'bagging_temperature': 0.7179890587888172, 'random_strength': 0.5200196706330242}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:46:52,208]\u001b[0m Trial 42 finished with value: 0.5589123035568481 and parameters: {'iterations': 546, 'learning_rate': 0.06693587595134487, 'depth': 5, 'l2_leaf_reg': 0.0008021221067861827, 'bagging_temperature': 0.47652795186983016, 'random_strength': 0.6071482578638105}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:47:03,535]\u001b[0m Trial 43 finished with value: 0.5589765231511638 and parameters: {'iterations': 609, 'learning_rate': 0.071895641488717, 'depth': 4, 'l2_leaf_reg': 2.2357801072733365e-05, 'bagging_temperature': 0.8375646690018024, 'random_strength': 0.2849738022349235}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:47:15,784]\u001b[0m Trial 44 finished with value: 0.558279281841451 and parameters: {'iterations': 782, 'learning_rate': 0.07660475429864728, 'depth': 3, 'l2_leaf_reg': 0.0003914756659068288, 'bagging_temperature': 0.9830957053315577, 'random_strength': 0.4913521072956777}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:47:31,330]\u001b[0m Trial 45 finished with value: 0.5565453527949284 and parameters: {'iterations': 452, 'learning_rate': 0.06278239568323707, 'depth': 7, 'l2_leaf_reg': 0.00010463563753414836, 'bagging_temperature': 0.38228954795629894, 'random_strength': 0.40812339297935274}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:47:42,735]\u001b[0m Trial 46 finished with value: 0.5579123127310759 and parameters: {'iterations': 519, 'learning_rate': 0.08584434092818315, 'depth': 5, 'l2_leaf_reg': 0.006870064192352715, 'bagging_temperature': 0.6750823153875133, 'random_strength': 0.3505971381745998}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:47:49,784]\u001b[0m Trial 47 finished with value: 0.5583801983468042 and parameters: {'iterations': 578, 'learning_rate': 0.07967397738810059, 'depth': 3, 'l2_leaf_reg': 2.0358004005816955e-06, 'bagging_temperature': 0.7888839632304119, 'random_strength': 0.6708702354942475}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:48:02,108]\u001b[0m Trial 48 finished with value: 0.5597471582829515 and parameters: {'iterations': 678, 'learning_rate': 0.07189024949945587, 'depth': 4, 'l2_leaf_reg': 8.933666032820918e-06, 'bagging_temperature': 0.5560756218019739, 'random_strength': 0.4863907032501534}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:49:37,931]\u001b[0m Trial 49 finished with value: 0.5423161255401326 and parameters: {'iterations': 624, 'learning_rate': 0.06477487785559152, 'depth': 10, 'l2_leaf_reg': 4.699635336191177e-05, 'bagging_temperature': 0.30337300887312824, 'random_strength': 0.3550365462999713}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:50:29,450]\u001b[0m Trial 50 finished with value: 0.5497380757974697 and parameters: {'iterations': 927, 'learning_rate': 0.05398739704338839, 'depth': 8, 'l2_leaf_reg': 6.588856289152246e-06, 'bagging_temperature': 0.3796547363660503, 'random_strength': 0.41788832099558526}. Best is trial 21 with value: 0.5600957789378079.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:50:40,441]\u001b[0m Trial 51 finished with value: 0.5601324758488454 and parameters: {'iterations': 582, 'learning_rate': 0.07979867991490328, 'depth': 4, 'l2_leaf_reg': 5.6652836374299495e-05, 'bagging_temperature': 0.6019234681749731, 'random_strength': 0.4489554356699457}. Best is trial 51 with value: 0.5601324758488454.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:50:51,188]\u001b[0m Trial 52 finished with value: 0.5594902799056889 and parameters: {'iterations': 561, 'learning_rate': 0.07540890052976607, 'depth': 4, 'l2_leaf_reg': 2.084716299307951e-05, 'bagging_temperature': 0.5761348136597367, 'random_strength': 0.4461729689318269}. Best is trial 51 with value: 0.5601324758488454.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:50:56,622]\u001b[0m Trial 53 finished with value: 0.5595636737277639 and parameters: {'iterations': 378, 'learning_rate': 0.08735255409710767, 'depth': 4, 'l2_leaf_reg': 1.0080838204997248e-06, 'bagging_temperature': 0.5157523185822277, 'random_strength': 0.28357132587710115}. Best is trial 51 with value: 0.5601324758488454.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:51:08,394]\u001b[0m Trial 54 finished with value: 0.5590040458344419 and parameters: {'iterations': 744, 'learning_rate': 0.08204124237975549, 'depth': 3, 'l2_leaf_reg': 0.0001493587511836159, 'bagging_temperature': 0.6312083156438455, 'random_strength': 0.36412904833528237}. Best is trial 51 with value: 0.5601324758488454.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:51:22,165]\u001b[0m Trial 55 finished with value: 0.5569306703608223 and parameters: {'iterations': 649, 'learning_rate': 0.09406568694317113, 'depth': 5, 'l2_leaf_reg': 3.777075589065764e-05, 'bagging_temperature': 0.5914290616618458, 'random_strength': 0.4796994831511558}. Best is trial 51 with value: 0.5601324758488454.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:51:29,097]\u001b[0m Trial 56 finished with value: 0.559371014944817 and parameters: {'iterations': 486, 'learning_rate': 0.09965822763110002, 'depth': 4, 'l2_leaf_reg': 0.00018678699294605465, 'bagging_temperature': 0.44696781665236907, 'random_strength': 0.32414967296196734}. Best is trial 51 with value: 0.5601324758488454.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:51:36,973]\u001b[0m Trial 57 finished with value: 0.5580682746029852 and parameters: {'iterations': 421, 'learning_rate': 0.08391082465804459, 'depth': 3, 'l2_leaf_reg': 6.36206854731917e-05, 'bagging_temperature': 0.540718999742529, 'random_strength': 0.41977049005085026}. Best is trial 51 with value: 0.5601324758488454.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:51:49,665]\u001b[0m Trial 58 finished with value: 0.5571416775992881 and parameters: {'iterations': 591, 'learning_rate': 0.0881899508814898, 'depth': 5, 'l2_leaf_reg': 1.5755477846756505e-05, 'bagging_temperature': 0.4839733979767919, 'random_strength': 0.2493942347293967}. Best is trial 51 with value: 0.5601324758488454.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:52:00,513]\u001b[0m Trial 59 finished with value: 0.5590682654287575 and parameters: {'iterations': 681, 'learning_rate': 0.0777158519570881, 'depth': 4, 'l2_leaf_reg': 4.853130787359792e-06, 'bagging_temperature': 0.6587745765298515, 'random_strength': 0.5262428772794555}. Best is trial 51 with value: 0.5601324758488454.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:52:10,948]\u001b[0m Trial 60 finished with value: 0.559444408766892 and parameters: {'iterations': 537, 'learning_rate': 0.06961766914931196, 'depth': 5, 'l2_leaf_reg': 9.071194012067035e-06, 'bagging_temperature': 0.05074999799981151, 'random_strength': 0.374042314770873}. Best is trial 51 with value: 0.5601324758488454.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:52:22,235]\u001b[0m Trial 61 finished with value: 0.559297621122742 and parameters: {'iterations': 601, 'learning_rate': 0.07928100223041615, 'depth': 4, 'l2_leaf_reg': 4.0334022319981316e-05, 'bagging_temperature': 0.6096687322282569, 'random_strength': 0.45210390439448883}. Best is trial 51 with value: 0.5601324758488454.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:52:32,627]\u001b[0m Trial 62 finished with value: 0.5588389097347731 and parameters: {'iterations': 627, 'learning_rate': 0.08329561044793005, 'depth': 3, 'l2_leaf_reg': 8.559174106121742e-05, 'bagging_temperature': 0.5269847257981792, 'random_strength': 0.43666147940644173}. Best is trial 51 with value: 0.5601324758488454.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:52:38,880]\u001b[0m Trial 63 finished with value: 0.5602884377207549 and parameters: {'iterations': 438, 'learning_rate': 0.0866101474945002, 'depth': 4, 'l2_leaf_reg': 0.00027243646963697496, 'bagging_temperature': 0.5853753081072699, 'random_strength': 0.49408984645491155}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:52:47,439]\u001b[0m Trial 64 finished with value: 0.5589856973789231 and parameters: {'iterations': 400, 'learning_rate': 0.09356350691275267, 'depth': 4, 'l2_leaf_reg': 0.00023659783868115877, 'bagging_temperature': 0.415114144605841, 'random_strength': 0.5549755316123739}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:52:53,907]\u001b[0m Trial 65 finished with value: 0.5592334015284264 and parameters: {'iterations': 454, 'learning_rate': 0.07388936577675585, 'depth': 4, 'l2_leaf_reg': 0.0006595636783658735, 'bagging_temperature': 0.4543195967008273, 'random_strength': 0.4822361059048449}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:53:39,092]\u001b[0m Trial 66 finished with value: 0.5428941018889735 and parameters: {'iterations': 505, 'learning_rate': 0.08643712542361813, 'depth': 9, 'l2_leaf_reg': 0.0003484126925560523, 'bagging_temperature': 0.5812445784533385, 'random_strength': 0.40498856965687324}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:53:44,764]\u001b[0m Trial 67 finished with value: 0.5543710608159558 and parameters: {'iterations': 225, 'learning_rate': 0.08218644396156564, 'depth': 3, 'l2_leaf_reg': 0.0013642609951122831, 'bagging_temperature': 0.4922228501573494, 'random_strength': 0.5082142929771324}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:53:52,200]\u001b[0m Trial 68 finished with value: 0.5593434922615389 and parameters: {'iterations': 441, 'learning_rate': 0.09047852070112317, 'depth': 5, 'l2_leaf_reg': 0.0005490904447574755, 'bagging_temperature': 0.00017672555999964645, 'random_strength': 0.337291846945397}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:53:59,555]\u001b[0m Trial 69 finished with value: 0.5587012963183824 and parameters: {'iterations': 313, 'learning_rate': 0.08578666135848695, 'depth': 4, 'l2_leaf_reg': 0.0001287770235356284, 'bagging_temperature': 0.18412347501544649, 'random_strength': 0.3114098614139379}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:54:06,417]\u001b[0m Trial 70 finished with value: 0.5597196355996734 and parameters: {'iterations': 476, 'learning_rate': 0.07726181353770592, 'depth': 4, 'l2_leaf_reg': 2.543305451579856e-05, 'bagging_temperature': 0.6509615853138081, 'random_strength': 0.3824249427247341}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:54:17,242]\u001b[0m Trial 71 finished with value: 0.5598297263327859 and parameters: {'iterations': 564, 'learning_rate': 0.08083152682938943, 'depth': 4, 'l2_leaf_reg': 6.915711064041499e-05, 'bagging_temperature': 0.6063001954282359, 'random_strength': 0.4637001767349869}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:54:27,100]\u001b[0m Trial 72 finished with value: 0.560123301621086 and parameters: {'iterations': 558, 'learning_rate': 0.08074652116240634, 'depth': 4, 'l2_leaf_reg': 7.382627254626542e-05, 'bagging_temperature': 0.5996910948006893, 'random_strength': 0.45629497869428964}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:54:35,765]\u001b[0m Trial 73 finished with value: 0.5593801891725764 and parameters: {'iterations': 557, 'learning_rate': 0.07417071686447847, 'depth': 4, 'l2_leaf_reg': 6.884174643441799e-05, 'bagging_temperature': 0.6188418979188981, 'random_strength': 0.45361578773078315}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:54:49,676]\u001b[0m Trial 74 finished with value: 0.5571967229658443 and parameters: {'iterations': 663, 'learning_rate': 0.08022042808533596, 'depth': 5, 'l2_leaf_reg': 0.0002210826380547426, 'bagging_temperature': 0.701476523786676, 'random_strength': 0.5244064794146557}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:55:00,050]\u001b[0m Trial 75 finished with value: 0.5595636737277639 and parameters: {'iterations': 527, 'learning_rate': 0.08804276636788316, 'depth': 4, 'l2_leaf_reg': 1.3901049418240221e-05, 'bagging_temperature': 0.5864982725490656, 'random_strength': 0.5844734079048125}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:55:07,828]\u001b[0m Trial 76 finished with value: 0.5584811148521573 and parameters: {'iterations': 632, 'learning_rate': 0.07854259243829506, 'depth': 3, 'l2_leaf_reg': 0.00012441352286161317, 'bagging_temperature': 0.5290129572787126, 'random_strength': 0.47659381990134253}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:55:20,340]\u001b[0m Trial 77 finished with value: 0.5585361602187136 and parameters: {'iterations': 581, 'learning_rate': 0.07056390125919511, 'depth': 5, 'l2_leaf_reg': 8.515166874977151e-05, 'bagging_temperature': 0.6806483842040119, 'random_strength': 0.42460960174035806}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:55:33,072]\u001b[0m Trial 78 finished with value: 0.5587746901404574 and parameters: {'iterations': 704, 'learning_rate': 0.05979522032800104, 'depth': 4, 'l2_leaf_reg': 0.0002840832932534717, 'bagging_temperature': 0.6360949410868454, 'random_strength': 0.507081606612084}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:55:43,146]\u001b[0m Trial 79 finished with value: 0.5598205521050266 and parameters: {'iterations': 504, 'learning_rate': 0.08422894955377384, 'depth': 4, 'l2_leaf_reg': 2.707790562924929e-05, 'bagging_temperature': 0.5554062285719031, 'random_strength': 0.46349501261489234}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:55:48,001]\u001b[0m Trial 80 finished with value: 0.5582701076136917 and parameters: {'iterations': 389, 'learning_rate': 0.08201267903171736, 'depth': 3, 'l2_leaf_reg': 3.462366305165161e-05, 'bagging_temperature': 0.5634994771016922, 'random_strength': 0.549564651899325}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:55:57,880]\u001b[0m Trial 81 finished with value: 0.559371014944817 and parameters: {'iterations': 500, 'learning_rate': 0.08463241455414083, 'depth': 4, 'l2_leaf_reg': 2.779199780157806e-05, 'bagging_temperature': 0.6052755576538341, 'random_strength': 0.46192668945210513}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:56:05,752]\u001b[0m Trial 82 finished with value: 0.5595361510444858 and parameters: {'iterations': 550, 'learning_rate': 0.07630329172060843, 'depth': 4, 'l2_leaf_reg': 6.505542758308258e-05, 'bagging_temperature': 0.5442146692222494, 'random_strength': 0.39726154824446935}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:56:14,668]\u001b[0m Trial 83 finished with value: 0.5593526664892983 and parameters: {'iterations': 423, 'learning_rate': 0.0810102060682196, 'depth': 4, 'l2_leaf_reg': 0.00018124276661241076, 'bagging_temperature': 0.5057209754060348, 'random_strength': 0.4348323732410197}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:56:26,147]\u001b[0m Trial 84 finished with value: 0.5593893634003357 and parameters: {'iterations': 610, 'learning_rate': 0.08847695882015881, 'depth': 4, 'l2_leaf_reg': 1.51325532262721e-05, 'bagging_temperature': 0.7484423656252047, 'random_strength': 0.49300902384162637}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:56:35,102]\u001b[0m Trial 85 finished with value: 0.5589123035568481 and parameters: {'iterations': 528, 'learning_rate': 0.07212552332830538, 'depth': 5, 'l2_leaf_reg': 0.00010641676279752835, 'bagging_temperature': 0.6446912949901022, 'random_strength': 0.3566163843965676}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:56:45,302]\u001b[0m Trial 86 finished with value: 0.5596003706388015 and parameters: {'iterations': 577, 'learning_rate': 0.08514108698525599, 'depth': 3, 'l2_leaf_reg': 0.0004125619741929827, 'bagging_temperature': 0.5722700126089407, 'random_strength': 0.5323978653535149}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:56:55,241]\u001b[0m Trial 87 finished with value: 0.5593526664892983 and parameters: {'iterations': 469, 'learning_rate': 0.06732237220888422, 'depth': 4, 'l2_leaf_reg': 4.852193156461349e-05, 'bagging_temperature': 0.6146297069154031, 'random_strength': 0.402181119784123}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:57:04,758]\u001b[0m Trial 88 finished with value: 0.5584902890799167 and parameters: {'iterations': 558, 'learning_rate': 0.07925096311771307, 'depth': 5, 'l2_leaf_reg': 1.0068099082263679e-05, 'bagging_temperature': 0.5192414556489194, 'random_strength': 0.46830298888699234}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:57:16,950]\u001b[0m Trial 89 finished with value: 0.559444408766892 and parameters: {'iterations': 643, 'learning_rate': 0.0745996083240571, 'depth': 4, 'l2_leaf_reg': 3.399083202797511e-05, 'bagging_temperature': 0.47606521870167684, 'random_strength': 0.49833267074295334}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:57:30,152]\u001b[0m Trial 90 finished with value: 0.5581508426528197 and parameters: {'iterations': 492, 'learning_rate': 0.09024820292156505, 'depth': 3, 'l2_leaf_reg': 0.0001534736748932549, 'bagging_temperature': 0.5882623549505084, 'random_strength': 0.4370875810338614}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:57:42,319]\u001b[0m Trial 91 finished with value: 0.5598939459271016 and parameters: {'iterations': 602, 'learning_rate': 0.08392734141122109, 'depth': 4, 'l2_leaf_reg': 1.8554500333288454e-05, 'bagging_temperature': 0.4334889912352469, 'random_strength': 0.41933297413525455}. Best is trial 63 with value: 0.5602884377207549.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:57:53,868]\u001b[0m Trial 92 finished with value: 0.5606003614645737 and parameters: {'iterations': 603, 'learning_rate': 0.08362450840653286, 'depth': 4, 'l2_leaf_reg': 1.8332003326676167e-05, 'bagging_temperature': 0.4279380655443625, 'random_strength': 0.4199203193972682}. Best is trial 92 with value: 0.5606003614645737.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:58:02,318]\u001b[0m Trial 93 finished with value: 0.559903120154861 and parameters: {'iterations': 592, 'learning_rate': 0.08345761667168572, 'depth': 4, 'l2_leaf_reg': 7.01221627082609e-05, 'bagging_temperature': 0.465063812201457, 'random_strength': 0.46470410835586756}. Best is trial 92 with value: 0.5606003614645737.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:58:26,310]\u001b[0m Trial 94 finished with value: 0.5597563325107109 and parameters: {'iterations': 596, 'learning_rate': 0.08152876647421964, 'depth': 4, 'l2_leaf_reg': 6.674132959561126e-05, 'bagging_temperature': 0.46775424769227086, 'random_strength': 0.3758865414726096}. Best is trial 92 with value: 0.5606003614645737.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:58:49,566]\u001b[0m Trial 95 finished with value: 0.5492977128650196 and parameters: {'iterations': 674, 'learning_rate': 0.08665916973398023, 'depth': 7, 'l2_leaf_reg': 1.8908406438467147e-05, 'bagging_temperature': 0.4263494893891045, 'random_strength': 0.42385231863467215}. Best is trial 92 with value: 0.5606003614645737.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:59:00,612]\u001b[0m Trial 96 finished with value: 0.5589214777846074 and parameters: {'iterations': 622, 'learning_rate': 0.09211273708267097, 'depth': 4, 'l2_leaf_reg': 9.261317698682547e-05, 'bagging_temperature': 0.44690167306386974, 'random_strength': 0.49445771954917267}. Best is trial 92 with value: 0.5606003614645737.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:59:11,064]\u001b[0m Trial 97 finished with value: 0.5594627572224108 and parameters: {'iterations': 545, 'learning_rate': 0.0889327916722143, 'depth': 4, 'l2_leaf_reg': 5.137159710002234e-05, 'bagging_temperature': 0.392281851407264, 'random_strength': 0.3325321793558769}. Best is trial 92 with value: 0.5606003614645737.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:59:18,185]\u001b[0m Trial 98 finished with value: 0.5585728571297511 and parameters: {'iterations': 573, 'learning_rate': 0.0835682356233374, 'depth': 3, 'l2_leaf_reg': 0.00014797155318364987, 'bagging_temperature': 0.4990641097362257, 'random_strength': 0.3915334813140447}. Best is trial 92 with value: 0.5606003614645737.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:59:31,759]\u001b[0m Trial 99 finished with value: 0.5568389280832285 and parameters: {'iterations': 651, 'learning_rate': 0.07888711528328991, 'depth': 5, 'l2_leaf_reg': 0.00029974636460601995, 'bagging_temperature': 0.42095896832315405, 'random_strength': 0.4478288897017147}. Best is trial 92 with value: 0.5606003614645737.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(study_name=\"catboost\", direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IDhzOPovawyX",
    "outputId": "cbd294e9-25a1-41f8-8148-ef218de1e2f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial:\n",
      "  Value: 0.5606003614645737\n",
      "  Params: \n",
      "    iterations: 603\n",
      "    learning_rate: 0.08362450840653286\n",
      "    depth: 4\n",
      "    l2_leaf_reg: 1.8332003326676167e-05\n",
      "    bagging_temperature: 0.4279380655443625\n",
      "    random_strength: 0.4199203193972682\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cxr35Ejoawlr",
    "outputId": "e5962272-3b5e-4d86-a420-b41cf23763f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "blessé_hospitalisé       0.37      0.39      0.88      0.38      0.59      0.33     16918\n",
      "      blessé_léger       0.66      0.46      0.84      0.54      0.62      0.37     43737\n",
      "           indemne       0.73      0.71      0.81      0.72      0.76      0.57     45511\n",
      "               tué       0.11      0.62      0.86      0.18      0.73      0.52      2835\n",
      "\n",
      "       avg / total       0.63      0.56      0.84      0.58      0.68      0.45    109001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_Catboost = CatBoostClassifier(learning_rate=study.best_params['learning_rate'],\n",
    "                                    depth=study.best_params['depth'],\n",
    "                                    l2_leaf_reg=study.best_params['l2_leaf_reg'],\n",
    "                                    random_strength=study.best_params['random_strength'],\n",
    "                                    bagging_temperature=study.best_params['bagging_temperature'],\n",
    "                                    thread_count= -1,\n",
    "                                    iterations=340,\n",
    "                                    verbose=False,\n",
    "                                    one_hot_max_size=15,\n",
    "                                    early_stopping_rounds=50,\n",
    "                                    random_seed=42)\n",
    "clf = OneVsOneClassifier(model_Catboost)\n",
    "clf.fit(X_ru, y_ru)\n",
    "y_pred = clf.predict(X_test)\n",
    "score = classification_report_imbalanced(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-toh0kagd03",
    "outputId": "e1d7cfac-819b-42c2-af6b-7f02fe7fd91c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "blessé_hospitalisé       0.37      0.39      0.38     16918\n",
      "      blessé_léger       0.66      0.46      0.54     43737\n",
      "           indemne       0.73      0.71      0.72     45511\n",
      "               tué       0.11      0.62      0.18      2835\n",
      "\n",
      "          accuracy                           0.56    109001\n",
      "         macro avg       0.47      0.54      0.46    109001\n",
      "      weighted avg       0.63      0.56      0.58    109001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_DT7xf_uhoB"
   },
   "source": [
    "<h2>b.<font color='#BC8F8F'> Oversampling </font></h2>\n",
    "<blockquote>\n",
    "L'Oversampling (sur-échantillonnage) : dans cette technique, nous augmentons le nombre de données dans les classes minoritaires en dupliquant ou en générant des données synthétiques. Cela permet d'améliorer la capacité des classificateurs binaires à reconnaître les classes minoritaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ZNY5C2T21sd",
    "outputId": "374b96b4-90fe-4979-96f2-38950748fd76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes échantillon rOs : {'indemne': 106191, 'blessé_léger': 106191, 'blessé_hospitalisé': 106191, 'tué': 106191}\n"
     ]
    }
   ],
   "source": [
    "rOs = RandomOverSampler()\n",
    "X_ro, y_ro = rOs.fit_resample(X_train, y_train)\n",
    "print('Classes échantillon rOs :', dict(pd.Series(y_ro[\"gravite_accident\"]).value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8aqyfNn21YR",
    "outputId": "d7908155-ab05-4424-e44e-79602304ff19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------RandomForestClassifier----------------------\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "blessé_hospitalisé       0.46      0.45      0.45     16918\n",
      "      blessé_léger       0.64      0.61      0.62     43737\n",
      "           indemne       0.70      0.77      0.74     45511\n",
      "               tué       0.31      0.06      0.11      2835\n",
      "\n",
      "          accuracy                           0.64    109001\n",
      "         macro avg       0.53      0.47      0.48    109001\n",
      "      weighted avg       0.63      0.64      0.63    109001\n",
      "\n",
      "-----------------------GradientBoostingClassifier----------------------\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "blessé_hospitalisé       0.36      0.40      0.38     16918\n",
      "      blessé_léger       0.68      0.45      0.54     43737\n",
      "           indemne       0.72      0.72      0.72     45511\n",
      "               tué       0.11      0.60      0.18      2835\n",
      "\n",
      "          accuracy                           0.56    109001\n",
      "         macro avg       0.46      0.54      0.45    109001\n",
      "      weighted avg       0.63      0.56      0.58    109001\n",
      "\n",
      "-----------------------LogisticRegression----------------------\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "blessé_hospitalisé       0.35      0.37      0.36     16918\n",
      "      blessé_léger       0.66      0.43      0.52     43737\n",
      "           indemne       0.70      0.70      0.70     45511\n",
      "               tué       0.09      0.59      0.16      2835\n",
      "\n",
      "          accuracy                           0.54    109001\n",
      "         macro avg       0.45      0.52      0.44    109001\n",
      "      weighted avg       0.62      0.54      0.56    109001\n",
      "\n",
      "-----------------------xgb.XGBClassifier----------------------\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "blessé_hospitalisé       0.38      0.46      0.41     16918\n",
      "      blessé_léger       0.68      0.49      0.57     43737\n",
      "           indemne       0.73      0.73      0.73     45511\n",
      "               tué       0.12      0.48      0.19      2835\n",
      "\n",
      "          accuracy                           0.58    109001\n",
      "         macro avg       0.48      0.54      0.48    109001\n",
      "      weighted avg       0.64      0.58      0.60    109001\n",
      "\n",
      "-----------------------CatBoostClassifier----------------------\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "blessé_hospitalisé       0.37      0.44      0.40     16918\n",
      "      blessé_léger       0.68      0.48      0.56     43737\n",
      "           indemne       0.73      0.73      0.73     45511\n",
      "               tué       0.12      0.54      0.19      2835\n",
      "\n",
      "          accuracy                           0.58    109001\n",
      "         macro avg       0.48      0.55      0.47    109001\n",
      "      weighted avg       0.64      0.58      0.60    109001\n",
      "\n",
      "-----------------------CatBoostRegressor----------------------\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "blessé_hospitalisé       0.00      0.00      0.00     16918\n",
      "      blessé_léger       0.82      0.10      0.19     43737\n",
      "           indemne       0.67      0.75      0.71     45511\n",
      "               tué       0.05      0.95      0.10      2835\n",
      "\n",
      "          accuracy                           0.38    109001\n",
      "         macro avg       0.39      0.45      0.25    109001\n",
      "      weighted avg       0.61      0.38      0.37    109001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# Définir les modèles à tester\n",
    "models = [\n",
    "    ('RandomForestClassifier', RandomForestClassifier()),#, params_rf),\n",
    "    ('GradientBoostingClassifier', GradientBoostingClassifier()),#, params_gb), ('SVC', SVC()),#, params_svm)\n",
    "    ('LogisticRegression',LogisticRegression()),\n",
    "    ('xgb.XGBClassifier',xgb.XGBClassifier()),\n",
    "    ('CatBoostClassifier',CatBoostClassifier(iterations=100,verbose = False)),\n",
    "    ('CatBoostRegressor',CatBoostRegressor(iterations=1000,verbose = False))\n",
    "]\n",
    "\n",
    "# Boucle à travers chaque modèle et exécuter la recherche de grille\n",
    "best_model = None\n",
    "best_score = 0\n",
    "for name, model in models:\n",
    "    clf = OneVsOneClassifier(model)#GridSearchCV(model, params, cv=5))\n",
    "    clf.fit(X_ro, y_ro)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = metrics.classification_report(y_test, y_pred) #classification_report_imbalanced(y_test, y_pred)  #\n",
    "    print(f\"-----------------------{name}----------------------\")\n",
    "    print()\n",
    "    print(score)\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4-ipCNHhx1u"
   },
   "source": [
    "<blockquote>\n",
    "Les modèles xgb.XGBClassifier et CatBoostClassifier donnent encore les meilleurs résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B3E6qTC_OEwi",
    "outputId": "ee423fae-121d-4a31-ed98-06520cf97556"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------xgb.XGBClassifier----------------------\n",
      "\n",
      "                          pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "blessé_hospitalisé       0.38      0.46      0.86      0.41      0.63      0.38     16918\n",
      "      blessé_léger       0.68      0.49      0.84      0.57      0.64      0.40     43737\n",
      "           indemne       0.73      0.73      0.81      0.73      0.77      0.59     45511\n",
      "               tué       0.12      0.48      0.90      0.19      0.66      0.42      2835\n",
      "\n",
      "       avg / total       0.64      0.58      0.83      0.60      0.69      0.47    109001\n",
      "\n",
      "-----------------------CatBoostClassifier----------------------\n",
      "\n",
      "                          pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "blessé_hospitalisé       0.37      0.44      0.87      0.40      0.62      0.36     16918\n",
      "      blessé_léger       0.68      0.48      0.85      0.56      0.64      0.39     43737\n",
      "           indemne       0.73      0.73      0.81      0.73      0.77      0.58     45511\n",
      "               tué       0.12      0.54      0.89      0.19      0.69      0.46      2835\n",
      "\n",
      "       avg / total       0.64      0.58      0.84      0.60      0.69      0.47    109001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    ('xgb.XGBClassifier',xgb.XGBClassifier()),\n",
    "    ('CatBoostClassifier',CatBoostClassifier(iterations=100,verbose = False)),\n",
    "   \n",
    "]\n",
    "\n",
    "# Boucle à travers chaque modèle et exécuter la recherche de grille\n",
    "best_model = None\n",
    "best_score = 0\n",
    "for name, model in models:\n",
    "    clf = OneVsOneClassifier(model)#GridSearchCV(model, params, cv=5))\n",
    "    clf.fit(X_ro, y_ro)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = classification_report_imbalanced(y_test, y_pred)  #\n",
    "    print(f\"-----------------------{name}----------------------\")\n",
    "    print()\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XpkAQMHEuRK"
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "        learning_rate=0.03195356163967975,\n",
    "        depth=10,\n",
    "        border_count =23,\n",
    "        l2_leaf_reg = 0.08237152633194551,\n",
    "        bootstrap_type=\"Bayesian\",\n",
    "        random_strength = 1.1975085276422479e-05,\n",
    "        bagging_temperature=0.05830688932069261,\n",
    "        od_type=\"IncToDec\",\n",
    "        thread_count= -1,\n",
    "        iterations=100,\n",
    "        verbose=False,\n",
    "        one_hot_max_size=15,\n",
    "        early_stopping_rounds=50,\n",
    "        random_seed=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TmGEZuUGIFxz",
    "outputId": "40d26c77-1a82-48ba-b317-077acc46a7b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "blessé_hospitalisé       0.36      0.46      0.85      0.41      0.63      0.38     16918\n",
      "      blessé_léger       0.68      0.48      0.85      0.56      0.64      0.39     43737\n",
      "           indemne       0.73      0.72      0.81      0.73      0.77      0.58     45511\n",
      "               tué       0.12      0.52      0.90      0.20      0.68      0.45      2835\n",
      "\n",
      "       avg / total       0.64      0.58      0.84      0.60      0.69      0.47    109001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "onevone_clf = OneVsOneClassifier(model)\n",
    "onevone_clf.fit(X_ro, y_ro)\n",
    "y_pred = onevone_clf.predict(X_test)\n",
    "score = classification_report_imbalanced(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T5Rl9MCo_Pol",
    "outputId": "7b5cc15c-790f-4dc2-ae65-98b4e792e713"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "blessé_hospitalisé       0.36      0.46      0.85      0.41      0.63      0.38     16918\n",
      "      blessé_léger       0.68      0.48      0.85      0.56      0.64      0.39     43737\n",
      "           indemne       0.73      0.72      0.81      0.73      0.77      0.58     45511\n",
      "               tué       0.12      0.51      0.90      0.20      0.68      0.44      2835\n",
      "\n",
      "       avg / total       0.64      0.58      0.84      0.60      0.69      0.47    109001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model = CatBoostClassifier(iterations=100,verbose = False)\n",
    "clf = OneVsOneClassifier(model)\n",
    "clf.fit(X_ro, y_ro)\n",
    "y_pred = clf.predict(X_test)\n",
    "score = classification_report_imbalanced(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uoQSicGyjkAq",
    "outputId": "f87b1daf-626b-4723-8661-204744fefe5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5791781726773149\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9otZsUT7-8f"
   },
   "source": [
    "<h1><font color='#BC8F8F'> Optimisation Catboost </font></h1>\n",
    "\n",
    "Avec un GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHpJUU_I2zyl"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "\n",
    "# Définir les paramètres à tester\n",
    "\n",
    "params = {'estimator__learning_rate': [0.05, 0.1, 0.15,0.03195356163967975],\n",
    "           'estimator__depth': [4, 6, 8,10],\n",
    "           'estimator__l2_leaf_reg': [0.1, 0.5, 1, 5, 10],\n",
    "           'estimator__border_count': [16, 32, 64],\n",
    "           'estimator__od_type': ['IncToDec', 'Iter'],\n",
    "           'estimator__random_seed': [0, 42, 123],\n",
    "           'estimator__one_hot_max_size': [2, 4, 8],\n",
    "            'estimator__random_strength': [0.1, 0.5, 1],\n",
    "            'estimator__bagging_temperature': [0.5, 1, 2],\n",
    "            'estimator__bootstrap_type': ['Bayesian', 'Bernoulli'],\n",
    "            'estimator__early_stopping_rounds': [10, 20, 30]\n",
    "            }\n",
    "\n",
    "# Définir le classificateur sous-jacent\n",
    "catboost_clf = CatBoostClassifier(iterations=100, verbose = False)\n",
    "\n",
    "# Définir le classificateur OneVsOne avec CatBoost\n",
    "onevone_clf = OneVsOneClassifier(catboost_clf)\n",
    "\n",
    "# Effectuer la recherche de grille avec validation croisée\n",
    "grid_search = GridSearchCV(onevone_clf, params, cv=3)\n",
    "grid_search.fit(X_ro, y_ro)\n",
    "\n",
    "# Afficher les meilleurs paramètres et le score de validation croisée\n",
    "print(\"Meilleurs paramètres:\", grid_search.best_params_)\n",
    "print(\"Meilleur score de validation croisée:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8_utxK57g-v"
   },
   "source": [
    "<blockquote>\n",
    "\n",
    "**Après 9h d'exécution, le programme s'est intérrompu tout seul sans sortir de résultats.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6lj08YTb1nKl",
    "outputId": "e86a192f-b04d-4675-d073-88298980d688"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "blessé_hospitalisé       0.37      0.43      0.87      0.40      0.61      0.35     16918\n",
      "      blessé_léger       0.68      0.48      0.85      0.56      0.64      0.39     43737\n",
      "           indemne       0.74      0.72      0.81      0.73      0.77      0.58     45511\n",
      "               tué       0.11      0.59      0.88      0.19      0.72      0.50      2835\n",
      "\n",
      "       avg / total       0.64      0.57      0.84      0.60      0.69      0.47    109001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "\n",
    "# Définir les paramètres à tester\n",
    "\n",
    "params = {'learning_rate': 0.15,\n",
    "           'depth': 6,\n",
    "           'l2_leaf_reg': 10,\n",
    "           'border_count': 16,\n",
    "           'od_type': 'IncToDec',\n",
    "           'random_seed': 42,\n",
    "           'one_hot_max_size': 4,\n",
    "            'random_strength': 0.1,\n",
    "            'bagging_temperature': 0.5, \n",
    "            #'bootstrap_type': 'Bernoulli',\n",
    "            'early_stopping_rounds': 30\n",
    "            }\n",
    "\n",
    "# Définir le classificateur sous-jacent\n",
    "catboost_clf = CatBoostClassifier(iterations=100, verbose = False,**params)\n",
    "\n",
    "# Définir le classificateur OneVsOne avec CatBoost\n",
    "onevone_clf = OneVsOneClassifier(catboost_clf)\n",
    "\n",
    "onevone_clf.fit(X_ro, y_ro)\n",
    "y_pred = onevone_clf.predict(X_test)\n",
    "score = classification_report_imbalanced(y_test, y_pred)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FTwYe_T91m8n",
    "outputId": "70da9691-316d-4d5f-b7e5-a5adf545d754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5724626379574499\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Znnx7Es9AaJ"
   },
   "source": [
    "<h1><font color='#BC8F8F'> Optimisation Catboost </font> </h1>\n",
    "\n",
    "Avec avec la bibliothèque optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5P3rVFd2zdf"
   },
   "outputs": [],
   "source": [
    "from optuna import Trial, visualization\n",
    "import optuna\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             balanced_accuracy_score,\n",
    "                             precision_score,\n",
    "                             recall_score,\n",
    "                             f1_score,\n",
    "                             confusion_matrix,\n",
    "                             ConfusionMatrixDisplay,\n",
    "                             classification_report,\n",
    "                             fbeta_score,\n",
    "                             make_scorer,\n",
    "                             precision_recall_fscore_support,\n",
    "                             roc_auc_score, roc_curve,\n",
    "                             precision_recall_curve, auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "adaLhcUd2zMC"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100,150),\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 0.1),\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-6, 10),\n",
    "        'bagging_temperature': trial.suggest_uniform('bagging_temperature', 0, 1),\n",
    "        'random_strength': trial.suggest_uniform('random_strength', 0, 1),\n",
    "        'od_type': 'Iter',\n",
    "        'od_wait': 50,\n",
    "        'allow_writing_files': False\n",
    "    }\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X_ro, y_ro, verbose=False)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "    \n",
    "    #return metrics.classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GcjAM0yD2y36",
    "outputId": "1e0c8294-6033-4d73-d6b7-17f4687dab96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-17 05:15:44,408]\u001b[0m A new study created in memory with name: catboost\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:16:14,426]\u001b[0m Trial 0 finished with value: 0.5594811056779295 and parameters: {'iterations': 100, 'learning_rate': 0.087915942057524, 'depth': 6, 'l2_leaf_reg': 3.6886968503989798e-06, 'bagging_temperature': 0.7983666182135246, 'random_strength': 0.3984608088499697}. Best is trial 0 with value: 0.5594811056779295.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:17:32,856]\u001b[0m Trial 1 finished with value: 0.5698663315015459 and parameters: {'iterations': 104, 'learning_rate': 0.0466544483350505, 'depth': 10, 'l2_leaf_reg': 0.002664487544495952, 'bagging_temperature': 0.5155549000848004, 'random_strength': 0.8478624206695993}. Best is trial 1 with value: 0.5698663315015459.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:18:44,037]\u001b[0m Trial 2 finished with value: 0.5443986752415115 and parameters: {'iterations': 138, 'learning_rate': 0.01760467961485301, 'depth': 8, 'l2_leaf_reg': 0.6222954435767624, 'bagging_temperature': 0.6752886745022862, 'random_strength': 0.4180897122659488}. Best is trial 1 with value: 0.5698663315015459.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:19:15,611]\u001b[0m Trial 3 finished with value: 0.5596829386886358 and parameters: {'iterations': 107, 'learning_rate': 0.07745650419558246, 'depth': 6, 'l2_leaf_reg': 0.0011016330653035049, 'bagging_temperature': 0.5745127281568949, 'random_strength': 0.12344433905972252}. Best is trial 1 with value: 0.5698663315015459.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:19:42,853]\u001b[0m Trial 4 finished with value: 0.5283254282070806 and parameters: {'iterations': 108, 'learning_rate': 0.02746493867345004, 'depth': 4, 'l2_leaf_reg': 1.406015245768776e-06, 'bagging_temperature': 0.05570761120831447, 'random_strength': 0.3433220296400865}. Best is trial 1 with value: 0.5698663315015459.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:20:57,438]\u001b[0m Trial 5 finished with value: 0.576416730121742 and parameters: {'iterations': 124, 'learning_rate': 0.07129861917527237, 'depth': 9, 'l2_leaf_reg': 0.00024272801565522733, 'bagging_temperature': 0.040893134487854255, 'random_strength': 0.24269005056261328}. Best is trial 5 with value: 0.576416730121742.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:21:29,029]\u001b[0m Trial 6 finished with value: 0.5455546279391932 and parameters: {'iterations': 145, 'learning_rate': 0.06885783404639681, 'depth': 3, 'l2_leaf_reg': 0.01944692563894854, 'bagging_temperature': 0.6651783671089646, 'random_strength': 0.026531458040104816}. Best is trial 5 with value: 0.576416730121742.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:22:51,573]\u001b[0m Trial 7 finished with value: 0.5864625095182613 and parameters: {'iterations': 107, 'learning_rate': 0.09846491379916487, 'depth': 10, 'l2_leaf_reg': 1.709887802423147e-05, 'bagging_temperature': 0.8308522276990399, 'random_strength': 0.4806231947989159}. Best is trial 7 with value: 0.5864625095182613.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:23:28,279]\u001b[0m Trial 8 finished with value: 0.5620774121338337 and parameters: {'iterations': 143, 'learning_rate': 0.09695803326102359, 'depth': 5, 'l2_leaf_reg': 5.542550359863736e-05, 'bagging_temperature': 0.820888476246878, 'random_strength': 0.8106524732053885}. Best is trial 7 with value: 0.5864625095182613.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:24:02,159]\u001b[0m Trial 9 finished with value: 0.5447197732130898 and parameters: {'iterations': 108, 'learning_rate': 0.034355932376499636, 'depth': 6, 'l2_leaf_reg': 8.438275065959454e-06, 'bagging_temperature': 0.04548699001087775, 'random_strength': 0.10456383288757176}. Best is trial 7 with value: 0.5864625095182613.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:25:03,477]\u001b[0m Trial 10 finished with value: 0.5732240988614783 and parameters: {'iterations': 120, 'learning_rate': 0.0961064926536244, 'depth': 8, 'l2_leaf_reg': 4.764893497594049e-05, 'bagging_temperature': 0.9849715152855594, 'random_strength': 0.6246795076691217}. Best is trial 7 with value: 0.5864625095182613.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:26:36,639]\u001b[0m Trial 11 finished with value: 0.582673553453638 and parameters: {'iterations': 123, 'learning_rate': 0.06672139226725121, 'depth': 10, 'l2_leaf_reg': 0.00018048160976421392, 'bagging_temperature': 0.31623920696368246, 'random_strength': 0.26284858742497214}. Best is trial 7 with value: 0.5864625095182613.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:28:05,830]\u001b[0m Trial 12 finished with value: 0.5771047972036953 and parameters: {'iterations': 117, 'learning_rate': 0.055248218646482564, 'depth': 10, 'l2_leaf_reg': 4.5186563817171374e-05, 'bagging_temperature': 0.3556176268709966, 'random_strength': 0.5555723832931168}. Best is trial 7 with value: 0.5864625095182613.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:29:14,904]\u001b[0m Trial 13 finished with value: 0.5724075925908937 and parameters: {'iterations': 132, 'learning_rate': 0.08086856906110129, 'depth': 8, 'l2_leaf_reg': 0.0004745468513860095, 'bagging_temperature': 0.31299411786658476, 'random_strength': 0.2591235111662893}. Best is trial 7 with value: 0.5864625095182613.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:30:43,626]\u001b[0m Trial 14 finished with value: 0.5784809313676021 and parameters: {'iterations': 116, 'learning_rate': 0.059031333018438235, 'depth': 10, 'l2_leaf_reg': 0.015749600584275967, 'bagging_temperature': 0.39851496906456674, 'random_strength': 0.5192805306118506}. Best is trial 7 with value: 0.5864625095182613.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:32:01,453]\u001b[0m Trial 15 finished with value: 0.5792056953605931 and parameters: {'iterations': 130, 'learning_rate': 0.08717900325256764, 'depth': 9, 'l2_leaf_reg': 1.235505251125255e-05, 'bagging_temperature': 0.23185639994883683, 'random_strength': 0.6478913332521345}. Best is trial 7 with value: 0.5864625095182613.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:33:11,448]\u001b[0m Trial 16 finished with value: 0.5736644617939285 and parameters: {'iterations': 114, 'learning_rate': 0.06627855650841205, 'depth': 9, 'l2_leaf_reg': 2.1893648941500333e-06, 'bagging_temperature': 0.4357882185558419, 'random_strength': 0.2819710390335375}. Best is trial 7 with value: 0.5864625095182613.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:34:00,312]\u001b[0m Trial 17 finished with value: 0.5603710057705893 and parameters: {'iterations': 150, 'learning_rate': 0.04567202438341694, 'depth': 7, 'l2_leaf_reg': 0.00019325062329195587, 'bagging_temperature': 0.2317913761903646, 'random_strength': 0.9736391682970963}. Best is trial 7 with value: 0.5864625095182613.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:35:41,033]\u001b[0m Trial 18 finished with value: 0.5909578811203567 and parameters: {'iterations': 128, 'learning_rate': 0.09935593930133522, 'depth': 10, 'l2_leaf_reg': 1.7677318129410456e-05, 'bagging_temperature': 0.5459767798082134, 'random_strength': 0.44804295573807035}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:36:24,429]\u001b[0m Trial 19 finished with value: 0.5680865313162264 and parameters: {'iterations': 131, 'learning_rate': 0.0921705144066394, 'depth': 7, 'l2_leaf_reg': 1.3848723430225266e-05, 'bagging_temperature': 0.9753029439688004, 'random_strength': 0.4178876532253929}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:37:48,092]\u001b[0m Trial 20 finished with value: 0.5826460307703599 and parameters: {'iterations': 137, 'learning_rate': 0.09956205425597738, 'depth': 9, 'l2_leaf_reg': 2.538965366217137e-06, 'bagging_temperature': 0.5677823919848869, 'random_strength': 0.4874836670620951}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:39:21,952]\u001b[0m Trial 21 finished with value: 0.5845083990055137 and parameters: {'iterations': 124, 'learning_rate': 0.08160313445217256, 'depth': 10, 'l2_leaf_reg': 6.824572227062906e-05, 'bagging_temperature': 0.4804473898013239, 'random_strength': 0.3314468837887926}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:40:59,785]\u001b[0m Trial 22 finished with value: 0.5895450500454125 and parameters: {'iterations': 127, 'learning_rate': 0.09976789922009979, 'depth': 10, 'l2_leaf_reg': 1.0837142325212845e-06, 'bagging_temperature': 0.47569052877038787, 'random_strength': 0.47316187628510287}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:42:17,670]\u001b[0m Trial 23 finished with value: 0.5797286263428776 and parameters: {'iterations': 128, 'learning_rate': 0.09068834842846288, 'depth': 9, 'l2_leaf_reg': 1.3874471167189881e-06, 'bagging_temperature': 0.6801900970336832, 'random_strength': 0.5865850884901729}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:43:28,079]\u001b[0m Trial 24 finished with value: 0.5759947156448106 and parameters: {'iterations': 135, 'learning_rate': 0.09992376173501095, 'depth': 8, 'l2_leaf_reg': 1.1223543173125596e-05, 'bagging_temperature': 0.5770907331746485, 'random_strength': 0.5055028160862792}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:45:00,635]\u001b[0m Trial 25 finished with value: 0.5848478454326107 and parameters: {'iterations': 112, 'learning_rate': 0.08655149125858687, 'depth': 10, 'l2_leaf_reg': 1.0067814868778374e-06, 'bagging_temperature': 0.4571135752375887, 'random_strength': 0.690556977121129}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:46:35,737]\u001b[0m Trial 26 finished with value: 0.5799029366703058 and parameters: {'iterations': 120, 'learning_rate': 0.0928137890335606, 'depth': 9, 'l2_leaf_reg': 6.2460274956347744e-06, 'bagging_temperature': 0.7949520692909764, 'random_strength': 0.45409278467808895}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:48:32,040]\u001b[0m Trial 27 finished with value: 0.5899028449280281 and parameters: {'iterations': 127, 'learning_rate': 0.09967026341156304, 'depth': 10, 'l2_leaf_reg': 3.234367332443821e-05, 'bagging_temperature': 0.8684652192188416, 'random_strength': 0.5516792722682552}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:49:19,855]\u001b[0m Trial 28 finished with value: 0.5666370033302447 and parameters: {'iterations': 126, 'learning_rate': 0.07854093413523902, 'depth': 7, 'l2_leaf_reg': 5.358410988291669e-06, 'bagging_temperature': 0.9095769834616446, 'random_strength': 0.5422788157439646}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:50:35,895]\u001b[0m Trial 29 finished with value: 0.5742791350538069 and parameters: {'iterations': 133, 'learning_rate': 0.08673521421741583, 'depth': 8, 'l2_leaf_reg': 4.265107615837038e-06, 'bagging_temperature': 0.748963929471343, 'random_strength': 0.39342200299927615}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:51:15,913]\u001b[0m Trial 30 finished with value: 0.5605177934147393 and parameters: {'iterations': 141, 'learning_rate': 0.0915653027939815, 'depth': 5, 'l2_leaf_reg': 2.1879645587219448e-05, 'bagging_temperature': 0.6413718827519126, 'random_strength': 0.5906267321378909}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:52:33,610]\u001b[0m Trial 31 finished with value: 0.585801965119586 and parameters: {'iterations': 101, 'learning_rate': 0.09937004533425844, 'depth': 10, 'l2_leaf_reg': 2.409425537038882e-05, 'bagging_temperature': 0.8807721948365724, 'random_strength': 0.4498258355780692}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:54:06,741]\u001b[0m Trial 32 finished with value: 0.5879762570985587 and parameters: {'iterations': 120, 'learning_rate': 0.09402936204909342, 'depth': 10, 'l2_leaf_reg': 7.537010593881763e-06, 'bagging_temperature': 0.7255708830074163, 'random_strength': 0.4854172528529216}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:55:24,386]\u001b[0m Trial 33 finished with value: 0.5798662397592682 and parameters: {'iterations': 128, 'learning_rate': 0.09244551334513995, 'depth': 9, 'l2_leaf_reg': 4.6556655403154665e-06, 'bagging_temperature': 0.7485012734423894, 'random_strength': 0.682003297237586}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:56:55,725]\u001b[0m Trial 34 finished with value: 0.5861781084577206 and parameters: {'iterations': 120, 'learning_rate': 0.0850035410431102, 'depth': 10, 'l2_leaf_reg': 3.044884397537147e-06, 'bagging_temperature': 0.5446787778838614, 'random_strength': 0.4091947188675935}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:58:12,480]\u001b[0m Trial 35 finished with value: 0.5806001779800185 and parameters: {'iterations': 127, 'learning_rate': 0.09431370385014604, 'depth': 9, 'l2_leaf_reg': 1.5505747723258932e-06, 'bagging_temperature': 0.5169160176963069, 'random_strength': 0.5511394836147901}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 05:59:46,970]\u001b[0m Trial 36 finished with value: 0.5848661938881294 and parameters: {'iterations': 121, 'learning_rate': 0.0767503051942525, 'depth': 10, 'l2_leaf_reg': 1.057965493151792e-06, 'bagging_temperature': 0.5974418084952762, 'random_strength': 0.5004787843193166}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:01:08,357]\u001b[0m Trial 37 finished with value: 0.5814625553894001 and parameters: {'iterations': 135, 'learning_rate': 0.0895137091813879, 'depth': 9, 'l2_leaf_reg': 8.087133733144188e-05, 'bagging_temperature': 0.7152797588872224, 'random_strength': 0.36087727229816036}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:02:34,294]\u001b[0m Trial 38 finished with value: 0.5854992156035266 and parameters: {'iterations': 111, 'learning_rate': 0.08322376383177388, 'depth': 10, 'l2_leaf_reg': 2.6788878934783606e-05, 'bagging_temperature': 0.6223650132114094, 'random_strength': 0.43004498439517747}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:03:03,145]\u001b[0m Trial 39 finished with value: 0.5493527582315758 and parameters: {'iterations': 129, 'learning_rate': 0.09474680714317053, 'depth': 3, 'l2_leaf_reg': 7.296387829875009e-06, 'bagging_temperature': 0.5046639468017335, 'random_strength': 0.359531674214492}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:04:06,205]\u001b[0m Trial 40 finished with value: 0.5720406234805185 and parameters: {'iterations': 125, 'learning_rate': 0.07637066298336449, 'depth': 8, 'l2_leaf_reg': 0.0011469594590269782, 'bagging_temperature': 0.6688693621272771, 'random_strength': 0.47808572842129937}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:05:25,557]\u001b[0m Trial 41 finished with value: 0.5850588526710764 and parameters: {'iterations': 102, 'learning_rate': 0.0999726221727284, 'depth': 10, 'l2_leaf_reg': 1.7555481128325227e-05, 'bagging_temperature': 0.8531084336579836, 'random_strength': 0.46730345629976106}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:06:45,453]\u001b[0m Trial 42 finished with value: 0.5850680268988357 and parameters: {'iterations': 105, 'learning_rate': 0.09636656168209623, 'depth': 10, 'l2_leaf_reg': 2.876295105649829e-06, 'bagging_temperature': 0.8089305666480553, 'random_strength': 0.5143879380826705}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:07:57,110]\u001b[0m Trial 43 finished with value: 0.5783708406344896 and parameters: {'iterations': 117, 'learning_rate': 0.08898237706976617, 'depth': 9, 'l2_leaf_reg': 0.00010833734381770197, 'bagging_temperature': 0.7432691070711039, 'random_strength': 0.5945419359928793}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:09:29,550]\u001b[0m Trial 44 finished with value: 0.5880129540095962 and parameters: {'iterations': 122, 'learning_rate': 0.09503336831110178, 'depth': 10, 'l2_leaf_reg': 4.129772224629946e-05, 'bagging_temperature': 0.8368548450186776, 'random_strength': 0.325032844758528}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:11:05,195]\u001b[0m Trial 45 finished with value: 0.5887285437748278 and parameters: {'iterations': 122, 'learning_rate': 0.09509092021896237, 'depth': 10, 'l2_leaf_reg': 4.114214704699193e-05, 'bagging_temperature': 0.8971155639122965, 'random_strength': 0.20002849328733704}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:11:37,817]\u001b[0m Trial 46 finished with value: 0.5594535829946514 and parameters: {'iterations': 123, 'learning_rate': 0.09581881894787042, 'depth': 5, 'l2_leaf_reg': 0.0001254446475017384, 'bagging_temperature': 0.9228359503207103, 'random_strength': 0.19068118179090662}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:12:08,096]\u001b[0m Trial 47 finished with value: 0.555031605214631 and parameters: {'iterations': 122, 'learning_rate': 0.08890821617321602, 'depth': 4, 'l2_leaf_reg': 0.00036764754474183066, 'bagging_temperature': 0.9445897913502077, 'random_strength': 0.20434534153999412}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:13:20,325]\u001b[0m Trial 48 finished with value: 0.5779121292465207 and parameters: {'iterations': 118, 'learning_rate': 0.08448500730226943, 'depth': 9, 'l2_leaf_reg': 3.263440369970612e-05, 'bagging_temperature': 0.8686964937389713, 'random_strength': 0.31323951850668275}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:14:54,877]\u001b[0m Trial 49 finished with value: 0.5891505582517591 and parameters: {'iterations': 126, 'learning_rate': 0.09638677091718559, 'depth': 10, 'l2_leaf_reg': 5.9610095192465476e-05, 'bagging_temperature': 0.8956512477696927, 'random_strength': 0.400037677072274}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:16:03,470]\u001b[0m Trial 50 finished with value: 0.5755268300290823 and parameters: {'iterations': 133, 'learning_rate': 0.09725400942501608, 'depth': 8, 'l2_leaf_reg': 0.00010085588189607825, 'bagging_temperature': 0.9463875850947332, 'random_strength': 0.40042794536843723}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:17:39,195]\u001b[0m Trial 51 finished with value: 0.5894166108567811 and parameters: {'iterations': 126, 'learning_rate': 0.0949672248980172, 'depth': 10, 'l2_leaf_reg': 4.6250845719281735e-05, 'bagging_temperature': 0.892789735175543, 'random_strength': 0.3234348144791157}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:19:14,376]\u001b[0m Trial 52 finished with value: 0.5883615746644526 and parameters: {'iterations': 125, 'learning_rate': 0.08950984799602851, 'depth': 10, 'l2_leaf_reg': 5.317363114674731e-05, 'bagging_temperature': 0.8907557320375554, 'random_strength': 0.37549494408316175}. Best is trial 18 with value: 0.5909578811203567.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:20:54,220]\u001b[0m Trial 53 finished with value: 0.59135237291401 and parameters: {'iterations': 130, 'learning_rate': 0.0971437079228313, 'depth': 10, 'l2_leaf_reg': 0.0002596872149321549, 'bagging_temperature': 0.9844475697822128, 'random_strength': 0.2848702304055373}. Best is trial 53 with value: 0.59135237291401.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:22:34,464]\u001b[0m Trial 54 finished with value: 0.591618425519032 and parameters: {'iterations': 131, 'learning_rate': 0.09999470365420624, 'depth': 10, 'l2_leaf_reg': 0.00027142851080040625, 'bagging_temperature': 0.9805624694389574, 'random_strength': 0.2867348372055009}. Best is trial 54 with value: 0.591618425519032.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:23:53,333]\u001b[0m Trial 55 finished with value: 0.5825451142650068 and parameters: {'iterations': 130, 'learning_rate': 0.0989919187654945, 'depth': 9, 'l2_leaf_reg': 0.00033388759449070856, 'bagging_temperature': 0.9898760906949697, 'random_strength': 0.29693987593301885}. Best is trial 54 with value: 0.591618425519032.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:25:17,611]\u001b[0m Trial 56 finished with value: 0.5816001688057908 and parameters: {'iterations': 138, 'learning_rate': 0.09160664855160996, 'depth': 9, 'l2_leaf_reg': 0.0011249259719077836, 'bagging_temperature': 0.9680257932062574, 'random_strength': 0.2655230325384792}. Best is trial 54 with value: 0.591618425519032.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:27:00,568]\u001b[0m Trial 57 finished with value: 0.5890955128852029 and parameters: {'iterations': 135, 'learning_rate': 0.08740699463509993, 'depth': 10, 'l2_leaf_reg': 0.00018330608190873104, 'bagging_temperature': 0.9607416692578861, 'random_strength': 0.35841829561292493}. Best is trial 54 with value: 0.591618425519032.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:28:39,188]\u001b[0m Trial 58 finished with value: 0.5907101769708535 and parameters: {'iterations': 131, 'learning_rate': 0.09787051159632479, 'depth': 10, 'l2_leaf_reg': 0.0006017050539394904, 'bagging_temperature': 0.9899783655032965, 'random_strength': 0.3162931240552504}. Best is trial 54 with value: 0.591618425519032.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:29:59,683]\u001b[0m Trial 59 finished with value: 0.579811194392712 and parameters: {'iterations': 131, 'learning_rate': 0.08162157840462142, 'depth': 9, 'l2_leaf_reg': 0.0006184251496428735, 'bagging_temperature': 0.9867236492372354, 'random_strength': 0.24204684995226167}. Best is trial 54 with value: 0.591618425519032.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:31:44,320]\u001b[0m Trial 60 finished with value: 0.5918019100742195 and parameters: {'iterations': 138, 'learning_rate': 0.09801568792945778, 'depth': 10, 'l2_leaf_reg': 0.0021193298932844352, 'bagging_temperature': 0.9306050107422359, 'random_strength': 0.28939120742808666}. Best is trial 60 with value: 0.5918019100742195.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:33:29,691]\u001b[0m Trial 61 finished with value: 0.5918661296685351 and parameters: {'iterations': 138, 'learning_rate': 0.09785656546882394, 'depth': 10, 'l2_leaf_reg': 0.0028327368691937528, 'bagging_temperature': 0.9341915920000394, 'random_strength': 0.28451342060946294}. Best is trial 61 with value: 0.5918661296685351.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:35:17,192]\u001b[0m Trial 62 finished with value: 0.5906276089210191 and parameters: {'iterations': 139, 'learning_rate': 0.09131938132704015, 'depth': 10, 'l2_leaf_reg': 0.0029023108834311554, 'bagging_temperature': 0.9406646985612176, 'random_strength': 0.30128346893323205}. Best is trial 61 with value: 0.5918661296685351.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:37:08,949]\u001b[0m Trial 63 finished with value: 0.5918569554407758 and parameters: {'iterations': 142, 'learning_rate': 0.09222774595850765, 'depth': 10, 'l2_leaf_reg': 0.003150157872249491, 'bagging_temperature': 0.9292131774625606, 'random_strength': 0.28972168160657186}. Best is trial 61 with value: 0.5918661296685351.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:38:59,511]\u001b[0m Trial 64 finished with value: 0.5927285070779167 and parameters: {'iterations': 144, 'learning_rate': 0.09733899890544416, 'depth': 10, 'l2_leaf_reg': 0.004921652550747684, 'bagging_temperature': 0.999286187265041, 'random_strength': 0.23773273890356372}. Best is trial 64 with value: 0.5927285070779167.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:40:28,481]\u001b[0m Trial 65 finished with value: 0.5831230906138476 and parameters: {'iterations': 145, 'learning_rate': 0.09186689820546884, 'depth': 9, 'l2_leaf_reg': 0.0055641111611486865, 'bagging_temperature': 0.998502922620258, 'random_strength': 0.2344166157696772}. Best is trial 64 with value: 0.5927285070779167.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:42:21,966]\u001b[0m Trial 66 finished with value: 0.5913156760029724 and parameters: {'iterations': 149, 'learning_rate': 0.0869242637122821, 'depth': 10, 'l2_leaf_reg': 0.006431325370587746, 'bagging_temperature': 0.9384688637815879, 'random_strength': 0.14802791310241184}. Best is trial 64 with value: 0.5927285070779167.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:44:16,584]\u001b[0m Trial 67 finished with value: 0.5912973275474537 and parameters: {'iterations': 149, 'learning_rate': 0.08599787496593497, 'depth': 10, 'l2_leaf_reg': 0.005408482112440483, 'bagging_temperature': 0.9330821771178288, 'random_strength': 0.150921175573478}. Best is trial 64 with value: 0.5927285070779167.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:45:45,875]\u001b[0m Trial 68 finished with value: 0.5833065751690352 and parameters: {'iterations': 147, 'learning_rate': 0.093236876173639, 'depth': 9, 'l2_leaf_reg': 0.0016477323626983133, 'bagging_temperature': 0.9229725426849578, 'random_strength': 0.07516536095435489}. Best is trial 64 with value: 0.5927285070779167.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:47:37,501]\u001b[0m Trial 69 finished with value: 0.5919670461738883 and parameters: {'iterations': 144, 'learning_rate': 0.08898413515087597, 'depth': 10, 'l2_leaf_reg': 0.01581760636334798, 'bagging_temperature': 0.9639865152446867, 'random_strength': 0.2694361164717057}. Best is trial 64 with value: 0.5927285070779167.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:48:19,073]\u001b[0m Trial 70 finished with value: 0.5639581288245062 and parameters: {'iterations': 143, 'learning_rate': 0.08920287714245369, 'depth': 6, 'l2_leaf_reg': 0.026717848584141363, 'bagging_temperature': 0.9607833242924533, 'random_strength': 0.2862070281996466}. Best is trial 64 with value: 0.5927285070779167.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:50:07,590]\u001b[0m Trial 71 finished with value: 0.5927560297611949 and parameters: {'iterations': 141, 'learning_rate': 0.09692260432598347, 'depth': 10, 'l2_leaf_reg': 0.010259686687296928, 'bagging_temperature': 0.9193801784685263, 'random_strength': 0.262551161316752}. Best is trial 71 with value: 0.5927560297611949.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:51:55,269]\u001b[0m Trial 72 finished with value: 0.592178053412354 and parameters: {'iterations': 141, 'learning_rate': 0.09613640716882559, 'depth': 10, 'l2_leaf_reg': 0.012228650686314077, 'bagging_temperature': 0.9153905453744848, 'random_strength': 0.2705066887327289}. Best is trial 71 with value: 0.5927560297611949.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:53:44,238]\u001b[0m Trial 73 finished with value: 0.5911780625865818 and parameters: {'iterations': 141, 'learning_rate': 0.09313183247074319, 'depth': 10, 'l2_leaf_reg': 0.01457642020783415, 'bagging_temperature': 0.8494666970032747, 'random_strength': 0.232614052962757}. Best is trial 71 with value: 0.5927560297611949.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:55:33,288]\u001b[0m Trial 74 finished with value: 0.5922697956899478 and parameters: {'iterations': 142, 'learning_rate': 0.09719189102549142, 'depth': 10, 'l2_leaf_reg': 0.03315550357644631, 'bagging_temperature': 0.9221434752784857, 'random_strength': 0.25866970898517205}. Best is trial 71 with value: 0.5927560297611949.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:57:00,743]\u001b[0m Trial 75 finished with value: 0.5830221741084944 and parameters: {'iterations': 143, 'learning_rate': 0.09678905330963028, 'depth': 9, 'l2_leaf_reg': 0.034463279720069684, 'bagging_temperature': 0.9136360178954142, 'random_strength': 0.2458031626185112}. Best is trial 71 with value: 0.5927560297611949.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 06:58:47,080]\u001b[0m Trial 76 finished with value: 0.590673480059816 and parameters: {'iterations': 140, 'learning_rate': 0.09127850810577601, 'depth': 10, 'l2_leaf_reg': 0.050306604489577904, 'bagging_temperature': 0.8224837629153314, 'random_strength': 0.3472415848533637}. Best is trial 71 with value: 0.5927560297611949.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:00:40,194]\u001b[0m Trial 77 finished with value: 0.590746873881891 and parameters: {'iterations': 146, 'learning_rate': 0.08312221085724189, 'depth': 10, 'l2_leaf_reg': 0.009938277113506084, 'bagging_temperature': 0.8505170750145714, 'random_strength': 0.22170009296137727}. Best is trial 71 with value: 0.5927560297611949.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:02:07,210]\u001b[0m Trial 78 finished with value: 0.5834533628131852 and parameters: {'iterations': 142, 'learning_rate': 0.09373252229240232, 'depth': 9, 'l2_leaf_reg': 0.002002127406982609, 'bagging_temperature': 0.7973226078749345, 'random_strength': 0.2650749317311271}. Best is trial 71 with value: 0.5927560297611949.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:03:51,953]\u001b[0m Trial 79 finished with value: 0.5935817102595389 and parameters: {'iterations': 137, 'learning_rate': 0.09779493534348084, 'depth': 10, 'l2_leaf_reg': 0.0035131272191219736, 'bagging_temperature': 0.8726946069838628, 'random_strength': 0.18743461129328726}. Best is trial 79 with value: 0.5935817102595389.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:05:36,175]\u001b[0m Trial 80 finished with value: 0.5908019192484473 and parameters: {'iterations': 136, 'learning_rate': 0.08874166807617911, 'depth': 10, 'l2_leaf_reg': 0.0037581456405681394, 'bagging_temperature': 0.8769452213714322, 'random_strength': 0.189483488644139}. Best is trial 79 with value: 0.5935817102595389.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:07:25,285]\u001b[0m Trial 81 finished with value: 0.5932147411491637 and parameters: {'iterations': 144, 'learning_rate': 0.09738152450569292, 'depth': 10, 'l2_leaf_reg': 0.009325299092452272, 'bagging_temperature': 0.909785554784682, 'random_strength': 0.27065297681927025}. Best is trial 79 with value: 0.5935817102595389.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:09:17,249]\u001b[0m Trial 82 finished with value: 0.5925541967504885 and parameters: {'iterations': 145, 'learning_rate': 0.0969812613427741, 'depth': 10, 'l2_leaf_reg': 0.01059413634500309, 'bagging_temperature': 0.9083759209510787, 'random_strength': 0.17148550400651597}. Best is trial 79 with value: 0.5935817102595389.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:11:06,615]\u001b[0m Trial 83 finished with value: 0.5924991513839323 and parameters: {'iterations': 144, 'learning_rate': 0.09632584938674806, 'depth': 10, 'l2_leaf_reg': 0.01125769472753538, 'bagging_temperature': 0.9601233174252564, 'random_strength': 0.2146570716102108}. Best is trial 79 with value: 0.5935817102595389.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:12:36,255]\u001b[0m Trial 84 finished with value: 0.5831047421583289 and parameters: {'iterations': 144, 'learning_rate': 0.09527039727776263, 'depth': 9, 'l2_leaf_reg': 0.010710816098129754, 'bagging_temperature': 0.9596304920299061, 'random_strength': 0.16143717854903497}. Best is trial 79 with value: 0.5935817102595389.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:14:29,625]\u001b[0m Trial 85 finished with value: 0.5937651948147264 and parameters: {'iterations': 147, 'learning_rate': 0.09406966481231459, 'depth': 10, 'l2_leaf_reg': 0.06481625811676192, 'bagging_temperature': 0.9043940681326637, 'random_strength': 0.11439305053271476}. Best is trial 85 with value: 0.5937651948147264.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:15:17,528]\u001b[0m Trial 86 finished with value: 0.5712883368042495 and parameters: {'iterations': 147, 'learning_rate': 0.09678930300860072, 'depth': 7, 'l2_leaf_reg': 0.040921710530280986, 'bagging_temperature': 0.8727963119673043, 'random_strength': 0.11138078028948513}. Best is trial 85 with value: 0.5937651948147264.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:17:11,258]\u001b[0m Trial 87 finished with value: 0.5933064834267575 and parameters: {'iterations': 147, 'learning_rate': 0.09527345843700319, 'depth': 10, 'l2_leaf_reg': 0.07414138545710315, 'bagging_temperature': 0.9074734096035425, 'random_strength': 0.2155552823114639}. Best is trial 85 with value: 0.5937651948147264.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:19:04,488]\u001b[0m Trial 88 finished with value: 0.5928385978110292 and parameters: {'iterations': 147, 'learning_rate': 0.09398769116184573, 'depth': 10, 'l2_leaf_reg': 0.10604580437208919, 'bagging_temperature': 0.8283815336570376, 'random_strength': 0.17563815401675675}. Best is trial 85 with value: 0.5937651948147264.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:20:35,772]\u001b[0m Trial 89 finished with value: 0.58456344437207 and parameters: {'iterations': 150, 'learning_rate': 0.0910189396982536, 'depth': 9, 'l2_leaf_reg': 0.06859645944034777, 'bagging_temperature': 0.77937419724007, 'random_strength': 0.1704077469128303}. Best is trial 85 with value: 0.5937651948147264.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:22:31,061]\u001b[0m Trial 90 finished with value: 0.5920220915404446 and parameters: {'iterations': 147, 'learning_rate': 0.0937475907178569, 'depth': 10, 'l2_leaf_reg': 0.10005677509413942, 'bagging_temperature': 0.8231219991615428, 'random_strength': 0.09170787993198504}. Best is trial 85 with value: 0.5937651948147264.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:24:28,279]\u001b[0m Trial 91 finished with value: 0.5917560389354226 and parameters: {'iterations': 145, 'learning_rate': 0.09429856336972868, 'depth': 10, 'l2_leaf_reg': 0.021657932561897554, 'bagging_temperature': 0.908393766853437, 'random_strength': 0.17681463866461633}. Best is trial 85 with value: 0.5937651948147264.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:26:21,966]\u001b[0m Trial 92 finished with value: 0.5930679535050137 and parameters: {'iterations': 148, 'learning_rate': 0.09806802211387874, 'depth': 10, 'l2_leaf_reg': 0.08771003987793854, 'bagging_temperature': 0.8585010784370217, 'random_strength': 0.2117921229165589}. Best is trial 85 with value: 0.5937651948147264.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:28:17,925]\u001b[0m Trial 93 finished with value: 0.5935174906652233 and parameters: {'iterations': 148, 'learning_rate': 0.09835980772335859, 'depth': 10, 'l2_leaf_reg': 0.14223482861982606, 'bagging_temperature': 0.8610501723427483, 'random_strength': 0.21802934849490613}. Best is trial 85 with value: 0.5937651948147264.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:30:12,032]\u001b[0m Trial 94 finished with value: 0.5940037247364703 and parameters: {'iterations': 148, 'learning_rate': 0.09962845085613788, 'depth': 10, 'l2_leaf_reg': 0.16377485694566934, 'bagging_temperature': 0.8539308940033936, 'random_strength': 0.1320956089450429}. Best is trial 94 with value: 0.5940037247364703.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:32:07,479]\u001b[0m Trial 95 finished with value: 0.5926826359391199 and parameters: {'iterations': 148, 'learning_rate': 0.0904210440351233, 'depth': 10, 'l2_leaf_reg': 0.18557740263467914, 'bagging_temperature': 0.8436723704520832, 'random_strength': 0.20097206722472089}. Best is trial 94 with value: 0.5940037247364703.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:33:39,136]\u001b[0m Trial 96 finished with value: 0.5848478454326107 and parameters: {'iterations': 150, 'learning_rate': 0.09995773509114482, 'depth': 9, 'l2_leaf_reg': 0.274338545395799, 'bagging_temperature': 0.8643931309499185, 'random_strength': 0.1327862339161368}. Best is trial 94 with value: 0.5940037247364703.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:35:34,045]\u001b[0m Trial 97 finished with value: 0.593801891725764 and parameters: {'iterations': 148, 'learning_rate': 0.09862067911607228, 'depth': 10, 'l2_leaf_reg': 0.09053695587879085, 'bagging_temperature': 0.8323443451728127, 'random_strength': 0.1422890046791946}. Best is trial 94 with value: 0.5940037247364703.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:37:28,426]\u001b[0m Trial 98 finished with value: 0.5941963835194173 and parameters: {'iterations': 148, 'learning_rate': 0.09390617364658381, 'depth': 10, 'l2_leaf_reg': 0.09280889063234256, 'bagging_temperature': 0.7781329617421482, 'random_strength': 0.14108478144643194}. Best is trial 98 with value: 0.5941963835194173.\u001b[0m\n",
      "\u001b[32m[I 2023-03-17 07:39:21,936]\u001b[0m Trial 99 finished with value: 0.5923615379675415 and parameters: {'iterations': 148, 'learning_rate': 0.09374131795440489, 'depth': 10, 'l2_leaf_reg': 0.1119065343384993, 'bagging_temperature': 0.8111431136544797, 'random_strength': 0.1331834509559583}. Best is trial 98 with value: 0.5941963835194173.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(study_name=\"catboost\", direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdv9uhyD2ynN",
    "outputId": "fbe43785-01b1-476a-d06f-ce8c52f75933"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial:\n",
      "  Value: 0.5941963835194173\n",
      "  Params: \n",
      "    iterations: 148\n",
      "    learning_rate: 0.09390617364658381\n",
      "    depth: 10\n",
      "    l2_leaf_reg: 0.09280889063234256\n",
      "    bagging_temperature: 0.7781329617421482\n",
      "    random_strength: 0.14108478144643194\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nyYOkl_s2yVo",
    "outputId": "c183f39e-2fec-4630-f4a6-ba6ae86232c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "blessé_hospitalisé       0.41      0.53      0.86      0.46      0.67      0.44     16918\n",
      "      blessé_léger       0.66      0.54      0.81      0.59      0.66      0.43     43737\n",
      "           indemne       0.72      0.75      0.79      0.74      0.77      0.59     45511\n",
      "               tué       0.17      0.21      0.97      0.19      0.46      0.19      2835\n",
      "\n",
      "       avg / total       0.63      0.62      0.82      0.62      0.70      0.49    109001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_Catboost = CatBoostClassifier(learning_rate=study.best_params['learning_rate'],\n",
    "                                    depth=study.best_params['depth'],\n",
    "                                    l2_leaf_reg=study.best_params['l2_leaf_reg'],\n",
    "                                    random_strength=study.best_params['random_strength'],\n",
    "                                    bagging_temperature=study.best_params['bagging_temperature'],\n",
    "                                    thread_count= -1,\n",
    "                                    iterations=340,\n",
    "                                    verbose=False,\n",
    "                                    one_hot_max_size=15,\n",
    "                                    early_stopping_rounds=50,\n",
    "                                    random_seed=42)\n",
    "clf = OneVsOneClassifier(model_Catboost)\n",
    "clf.fit(X_ro, y_ro)\n",
    "y_pred = clf.predict(X_test)\n",
    "score = classification_report_imbalanced(y_test, y_pred)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
