import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import shap
from streamlit_shap import st_shap
import pickle
from PIL import Image
import os

############################
# Configuration de la page #
############################
st.set_page_config(
        page_title='Explication de la Pr√©diction',
        page_icon = "ü•á",
        layout="wide" )

# D√©finition de quelques styles css
st.markdown(""" 
            <style>
            body {font-family:'Roboto Condensed';}
            h1 {font-family:'Roboto Condensed';
                color:#603b1b;
                font-size:2.3em;
                font-style:italic;
                font-weight:700;
                margin:0px;}
            h2 {font-family:'Roboto Condensed';
                color:#8dc5bd;
                font-size:2em;
                font-style:italic;
                font-weight:700;
                margin:0px;}
            p {font-family:'Roboto Condensed'; color:Gray; font-size:1.125rem;}
            .css-1offfwp li {font-family:'Roboto Condensed'; color:Gray; font-size:1.125rem;}
            </style> """, 
            unsafe_allow_html=True)

st.markdown("""
            <h1>
            8. "Pourquoi le mod√®le a-t-il pr√©dit cette valeur ?"
            </h1>
            """, 
            unsafe_allow_html=True)

# Chargement du mod√®le
model_path = os.path.join('models', 'model_Catboost.pkl')
model = pickle.load(open(model_path, "rb"))

target_names = list(model.classes_)
# Rappel des num√©ros des classes et de leur libell√©
# 0:"bless√©_hospitalis√©"
# 1:"bless√©_l√©ger"
# 2:"indemne"
# 3:"tu√©"

# R√©cup√©rez la pr√©diction et les donn√©es d'entr√©e √† partir de st.session_state
if "prediction" not in st.session_state:
    st.session_state.prediction = None

if "probabilities" not in st.session_state:
    st.session_state.probabilities = None

if "input_data" not in st.session_state:
    st.session_state.input_data = None
    
prediction = st.session_state.prediction
probabilities = st.session_state.probabilities
input_data = st.session_state.input_data

# Initialisez une variable pour d√©terminer si l'erreur doit √™tre affich√©e
display_error = False

# V√©rifiez si les variables ont des valeurs valides
if prediction is None or probabilities is None or input_data is None:
    st.error("**Les informations requises sont manquantes. Veuillez retourner √† la page Mod√©lisation pour les fournir.**")
    st.error("**Cliquez sur 'Mod√©lisation' dans la barre lat√©rale pour retourner √† la page pr√©c√©dente.**")
    display_error = True

if not display_error:
    prob_df = pd.DataFrame(probabilities, columns=model.classes_)
    prob_df = prob_df[['indemne', 'bless√©_l√©ger', 'bless√©_hospitalis√©', 'tu√©']]

    prediction_value = prediction[0]
    index_prediction = target_names.index(prediction_value)
    #st.write(index_prediction)

    st.markdown("""
                ***Pour rappel, les modalit√©s des caract√©ristiques de l'accident que vous avez s√©lectionn√©es ont comme r√©sultats :***
                """)
    st.write(f"La pr√©diction de la gravit√© de l'accident est : **{prediction.item()}**")
    st.write(f"**La probabilit√© que l'usager de la route appartienne √† la classe {prediction.item()} \
            est de {probabilities.max():.1%}**.")
    st.write("Et, les probabilit√©s pour chaque classe sont (en %) :")
    st.write((prob_df * 100).round(1))

    # V√©rifiez si la pr√©diction et les donn√©es d'entr√©e sont disponibles
    if prediction is not None and input_data is not None:
        # Cr√©ez un explainer SHAP pour le mod√®le CatBoost
        explainer = shap.TreeExplainer(model)

        # Calculez les valeurs SHAP pour les donn√©es d'entr√©e
        shap_values = explainer.shap_values(input_data)
        
    else:
        st.markdown("""
                    Aucune pr√©diction n'est disponible pour l'explication. 
                    Veuillez d'abord effectuer une pr√©diction dans la page 04_üíª_Mod√©lisation.
                    """)

    st.markdown("""
                Pour comprendre et interpr√©ter visuellement les r√©sutats de la pr√©diction, il existe trois graphiques alternatifs : 
                `Force plot`, `Decision plot` et `Waterfall plot`.
                Ces trois repr√©sentations sont redondantes car elles repr√©sentent l‚Äôinformation de mani√®re tr√®s similaire. 
                En m√™me temps, certains √©l√©ments de ces graphiques sont compl√©mentaires. 
                En mettant c√¥te √† c√¥te les trois, on comprend d‚Äôune mani√®re plus intuitive le r√©sultat.
                """)
    st.markdown("""
                Le `Force plot` est bon pour voir o√π se place le ‚Äúoutput value‚Äù par rapport √† la ‚Äúbase value‚Äù. 
                Nous observons √©galement quelles variables ont un impact positif (rouge) ou n√©gatif (bleu) sur la pr√©diction 
                et l‚Äôamplitude de cet impact.
                """) 

    st_shap(shap.force_plot(explainer.expected_value[index_prediction], 
                            shap_values[index_prediction], 
                            input_data,
                            figsize=(20, 8),
                            ordering_keys=True,
                            text_rotation=0))

    st.markdown("""
                Le `Waterfall plot` permet aussi de voir l‚Äôamplitude et la nature d‚Äôimpact d‚Äôune variable avec sa quantification. 
                Il permet de voir √©galement l‚Äôordre d‚Äôimportance des variables et les valeurs prises par chacune des variables 
                pour l‚Äôinstance √©tudi√©e (l'accident que vous avez s√©lectionn√©), c'est-√†-dire qu'il affiche les contributions marginales
                de chaque variable pour l'observation sp√©cifique s√©lectionn√©e. 
                Les features qui ont une contribution positive sont affich√©es en rouge, tandis que les features qui ont une contribution n√©gative
                sont affich√©es en bleu. Chaque barre repr√©sente la contribution marginale de chaque feature √† la pr√©diction finale du mod√®le, 
                et la barre totale repr√©sente la pr√©diction moyenne du mod√®le pour l'ensemble des observations. 
                Le graphique permet de visualiser l'effet cumulatif des features sur la pr√©diction finale du mod√®le.
                """)

    shap.waterfall_plot(shap.Explanation(values=shap_values[index_prediction][0], 
                                        base_values=explainer.expected_value[index_prediction], 
                                        data=input_data.iloc[0],  
                                        feature_names=input_data.columns.tolist()),
                        max_display=15,
                        show=False)
    # Modifiez la taille du graphique
    plt.gcf().set_size_inches(14, 10)  # Modifiez les dimensions (largeur, hauteur) comme vous le souhaitez
    st.pyplot(plt.gcf())

    plt.clf()  # Nettoyez la figure courante

    st.markdown("""
                Le graphique ci-dessous appel√© `decision_plot` est une autre mani√®re de comprendre la pr√©diction.\
                Comme pour le graphique pr√©c√©dent, il met en √©vidence l‚Äôamplitude et la nature de l‚Äôimpact de chaque variable \
                avec sa quantification ainsi que leur ordre d‚Äôimportance. Mais surtout il permet d'observer \
                ‚Äúla trajectoire‚Äù prise par la pr√©diction de l'usager de la route pour chacune des valeurs des variables explicatives.
                """)

    shap.multioutput_decision_plot(explainer.expected_value, 
                                shap_values,
                                row_index=0,
                                feature_order='importance',
                                feature_names=input_data.columns.to_list(),
                                legend_labels=target_names,
                                feature_display_range=slice(None, -34, -1),
                                highlight=[np.argmax(probabilities[0])],
                                plot_color="BrBG_r",
                                legend_location='best',
                                show=False)
    plt.title(f"Diagramme de d√©cision\n", 
            fontsize=16, fontstyle='italic', fontweight='bold')
    plt.gcf().set_size_inches(10,10)
    st.pyplot(plt.gcf())

    plt.clf()  # Nettoyez la figure courante


    st.markdown("""
                Nous venons de comprendre et interpr√©ter visuellement les r√©sutats de la pr√©diction pour un usager de la route dont
                nous avons d√©fini les caract√©ristiques de l'accident.
                
                Maintenant, nous devons r√©pondre aux questions suivantes :
                1. Quelles sont les variables globalement les plus importantes pour comprendre la pr√©diction ?
                2. Quel est l'Impact de chaque caract√©ristique sur la pr√©diction de chaque classe ?
                
                *Cliquez sur "Explication globale du mod√®le" dans la barre lat√©rale gauche.*
                """
                )


# Centrage de l'image du logo dans la sidebar
col1, col2, col3 = st.columns([1,1,1])
with col1:
    st.sidebar.write("")
with col2:
    image_path = os.path.join('assets', 'logo-datascientest.png')
    logo = Image.open(image_path)
    st.sidebar.image(logo, use_column_width="always")
with col3:
    st.sidebar.write("")