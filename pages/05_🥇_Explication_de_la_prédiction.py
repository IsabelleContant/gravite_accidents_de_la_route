import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import shap
from streamlit_shap import st_shap
import pickle
from PIL import Image
import os

############################
# Configuration de la page #
############################
st.set_page_config(
        page_title='Explication de la Pr√©diction',
        page_icon = "ü•á",
        layout="wide" )

# D√©finition de quelques styles css
st.markdown(""" 
            <style>
            body {font-family:'Roboto Condensed';}
            h1 {font-family:'Roboto Condensed';
                color:#603b1b;
                font-size:2.3em;
                font-style:italic;
                font-weight:700;
                margin:0px;}
            h2 {font-family:'Roboto Condensed';
                color:#8dc5bd;
                font-size:2em;
                font-style:italic;
                font-weight:700;
                margin:0px;}
            p {font-family:'Roboto Condensed'; color:Gray; font-size:1.125rem;}
            .css-1offfwp li {font-family:'Roboto Condensed'; color:Gray; font-size:1.125rem;}
            </style> """, 
            unsafe_allow_html=True)

st.markdown("""
            <h1>
            8. "Pourquoi le mod√®le a-t-il pr√©dit cette valeur ?"
            </h1>
            """, 
            unsafe_allow_html=True)

# Chargement du mod√®le
model_path = os.path.join('models', 'model_Catboost.pkl')
model = pickle.load(open(model_path, "rb"))

target_names = list(model.classes_)
# Rappel des num√©ros des classes et de leur libell√©
# 0:"bless√©_hospitalis√©"
# 1:"bless√©_l√©ger"
# 2:"indemne"
# 3:"tu√©"

# R√©cup√©rez la pr√©diction et les donn√©es d'entr√©e √† partir de st.session_state
prediction = st.session_state.prediction
probabilities = st.session_state.probabilities
input_data = st.session_state.input_data
st.session_state.prob_df = pd.DataFrame(probabilities, columns=model.classes_)
st.session_state.prob_df = st.session_state.prob_df[['indemne', 'bless√©_l√©ger', 'bless√©_hospitalis√©', 'tu√©']]

prediction_value = prediction[0]
index_prediction = target_names.index(prediction_value)
#st.write(index_prediction)

st.markdown("""
            ***Pour rappel, les modalit√©s des caract√©ristiques de l'accident que vous avez s√©lectionn√©es ont comme r√©sultats :***
            """)
st.write(f"La pr√©diction de la gravit√© de l'accident est : **{st.session_state.prediction_text}**")
st.write(f"**La probabilit√© que l'usager de la route appartienne √† la classe {st.session_state.prediction_text} \
         est de {probabilities.max():.1%}**.")
st.write("Et, les probabilit√©s pour chaque classe sont (en %) :")
st.write((st.session_state.prob_df * 100).round(1))

# V√©rifiez si la pr√©diction et les donn√©es d'entr√©e sont disponibles
if prediction is not None and input_data is not None:
    # Cr√©ez un explainer SHAP pour le mod√®le CatBoost
    explainer = shap.TreeExplainer(model)

    # Calculez les valeurs SHAP pour les donn√©es d'entr√©e
    shap_values = explainer.shap_values(input_data)
    
else:
    st.markdown("""
                Aucune pr√©diction n'est disponible pour l'explication. 
                Veuillez d'abord effectuer une pr√©diction dans la page 04_üíª_Mod√©lisation.
                """)

st.markdown("""
            Pour comprendre et interpr√©ter visuellement les r√©sutats de la pr√©diction, il existe trois graphiques alternatifs : 
            `Force plot`, `Decision plot` et `Waterfall plot`.
            Ces trois repr√©sentations sont redondantes car elles repr√©sentent l‚Äôinformation de mani√®re tr√®s similaire. 
            En m√™me temps, certains √©l√©ments de ces graphiques sont compl√©mentaires. 
            En mettant c√¥te √† c√¥te les trois, on comprend d‚Äôune mani√®re plus intuitive le r√©sultat.
            """)
st.markdown("""
            Le `Force plot` est bon pour voir o√π se place le ‚Äúoutput value‚Äù par rapport √† la ‚Äúbase value‚Äù. 
            Nous observons √©galement quelles variables ont un impact positif (rouge) ou n√©gatif (bleu) sur la pr√©diction 
            et l‚Äôamplitude de cet impact.
            """) 

st_shap(shap.force_plot(explainer.expected_value[index_prediction], 
                        shap_values[index_prediction], 
                        input_data,
                        figsize=(20, 8),
                        ordering_keys=True,
                        text_rotation=0))

st.markdown("""
            Le `Waterfall plot` permet aussi de voir l‚Äôamplitude et la nature d‚Äôimpact d‚Äôune variable avec sa quantification. 
            Il permet de voir √©galement l‚Äôordre d‚Äôimportance des variables et les valeurs prises par chacune des variables 
            pour l‚Äôinstance √©tudi√©e (l'accident que vous avez s√©lectionn√©), c'est-√†-dire qu'il affiche les contributions marginales
            de chaque variable pour l'observation sp√©cifique s√©lectionn√©e. 
            Les features qui ont une contribution positive sont affich√©es en rouge, tandis que les features qui ont une contribution n√©gative
            sont affich√©es en bleu. Chaque barre repr√©sente la contribution marginale de chaque feature √† la pr√©diction finale du mod√®le, 
            et la barre totale repr√©sente la pr√©diction moyenne du mod√®le pour l'ensemble des observations. 
            Le graphique permet de visualiser l'effet cumulatif des features sur la pr√©diction finale du mod√®le.
            """)

shap.waterfall_plot(shap.Explanation(values=shap_values[index_prediction][0], 
                                     base_values=explainer.expected_value[index_prediction], 
                                     data=input_data.iloc[0],  
                                     feature_names=input_data.columns.tolist()),
                    max_display=15,
                    show=False)
# Modifiez la taille du graphique
plt.gcf().set_size_inches(14, 10)  # Modifiez les dimensions (largeur, hauteur) comme vous le souhaitez
st.pyplot(plt.gcf())

plt.clf()  # Nettoyez la figure courante

st.markdown("""
            Le graphique ci-dessous appel√© `decision_plot` est une autre mani√®re de comprendre la pr√©diction.\
            Comme pour le graphique pr√©c√©dent, il met en √©vidence l‚Äôamplitude et la nature de l‚Äôimpact de chaque variable \
            avec sa quantification ainsi que leur ordre d‚Äôimportance. Mais surtout il permet d'observer \
            ‚Äúla trajectoire‚Äù prise par la pr√©diction de l'usager de la route pour chacune des valeurs des variables explicatives.
            """)

shap.multioutput_decision_plot(explainer.expected_value, 
                               shap_values,
                               row_index=0,
                               feature_order='importance',
                               feature_names=input_data.columns.to_list(),
                               legend_labels=target_names,
                               feature_display_range=slice(None, -34, -1),
                               highlight=[np.argmax(probabilities[0])],
                               plot_color="BrBG_r",
                               legend_location='best',
                               show=False)
plt.title(f"Diagramme de d√©cision\n", 
          fontsize=16, fontstyle='italic', fontweight='bold')
plt.gcf().set_size_inches(10,10)
st.pyplot(plt.gcf())

plt.clf()  # Nettoyez la figure courante


st.markdown("""
            Nous venons de comprendre et interpr√©ter visuellement les r√©sutats de la pr√©diction pour un usager de la route dont
            nous avons d√©fini les caract√©ristiques de l'accident.
            
            Maintenant, nous devons r√©pondre aux questions suivantes :
            1. Quelles sont les variables globalement les plus importantes pour comprendre la pr√©diction ?
            2. Quel est l'Impact de chaque caract√©ristique sur la pr√©diction de chaque classe ?
            
            *Cliquez sur "Explication globale du mod√®le" dans la barre lat√©rale gauche.*
            """
            )


# Centrage de l'image du logo dans la sidebar
col1, col2, col3 = st.columns([1,1,1])
with col1:
    st.sidebar.write("")
with col2:
    image_path = os.path.join('assets', 'logo-datascientest.png')
    logo = Image.open(image_path)
    st.sidebar.image(logo, use_column_width="always")
with col3:
    st.sidebar.write("")